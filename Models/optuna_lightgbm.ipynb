{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_15_19_45\n",
      "/home/tomita/kaggle/kaggle_elo/Models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import gc \n",
    "import time\n",
    "import optuna\n",
    "import sklearn.metrics\n",
    "from datetime import datetime \n",
    "\n",
    "plt.style.use('ggplot') # Lets make our plots pretty\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "n=datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "print(str(n))\n",
    "print(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917,)\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataframes\n",
    "train = pd.read_csv('../input/train_1.csv')\n",
    "test = pd.read_csv('../input/test_1.csv')\n",
    "\n",
    "#print(train.columns)\n",
    "\n",
    "target = train['target']\n",
    "train_true=np.array(train['target'])\n",
    "print(train_true.shape)\n",
    "                    \n",
    "del train['target']\n",
    "del train['outliers']\n",
    "#del train['outliners']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_lightgbm(trial):\n",
    "    FEATS_EXCLUDED = ['first_active_month', 'target', 'card_id', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "                  'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size',\n",
    "                  'OOF_PRED', 'month_0','outliers']\n",
    "    seed=20190208\n",
    "        \n",
    "    # params optimized by optuna\n",
    "    learning_rate_tuna = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    toprate_tuna = trial.suggest_uniform('top_rate', 0, 1.0)\n",
    "    num_leaves_tuna = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    min_child_weight_tuna = trial.suggest_int('min_child_weight', 5, 500)\n",
    "    other_rate_tuna=trial.suggest_uniform('other_rate', 0.0, 1.0)\n",
    "    num_leaves_tuna=trial.suggest_int('num_leaves', 5, 1000)\n",
    "    min_gain_split_tuna=trial.suggest_uniform('min_gain_split', 5, 500)\n",
    "    reg_lambda_tuna=trial.suggest_uniform('reg_lambda', 5, 500)\n",
    "    subsample_tuna = trial.suggest_uniform('sub_sample', 0, 1.0)\n",
    "    reg_alpha_tuna=trial.suggest_uniform('sub_sample', 0, 20)\n",
    "    colsample_bytree_tuna = trial.suggest_uniform('colsample_bytree_tuna', 0, 1.0)\n",
    "    max_depth= trial.suggest_int('max_depth', 5, 100)\n",
    "    \n",
    "    param ={'task': 'train',\n",
    "            'boosting': 'dart',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': learning_rate_tuna ,\n",
    "            'subsample': subsample_tuna,\n",
    "            'max_depth': max_depth,\n",
    "            'top_rate': toprate_tuna ,\n",
    "            'num_leaves': num_leaves_tuna,\n",
    "            'min_child_weight': min_child_weight_tuna,\n",
    "            'other_rate': other_rate_tuna,\n",
    "            'reg_alpha': reg_alpha_tuna,\n",
    "            'colsample_bytree':colsample_bytree_tuna  ,\n",
    "            'min_split_gain': min_gain_split_tuna,\n",
    "            'reg_lambda': reg_lambda_tuna,\n",
    "            'min_data_in_leaf': 21,\n",
    "            'verbose': -1,\n",
    "            'seed':seed,\n",
    "            'bagging_seed':seed,\n",
    "            'drop_seed':seed,\n",
    "            'max_bin':255,\n",
    "            'device':'gpu'\n",
    "            }\n",
    "\n",
    "    # Create arrays and dataframes to store results\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    train_prdictions = np.zeros(train.shape[0])\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    # k-fold\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "        train_prdictions += clf.predict(train[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    n=datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "    feature_importance_df.to_csv(\"../output/feature_importance.csv\")\n",
    "    sub_df = pd.read_csv(\"../input/sample_submission.csv\",engine='python')\n",
    "    sub_df[\"target\"] = predictions\n",
    "    sub_df.to_csv(\"../output/submit_lgb\"+str(n)+\"_optuna.csv\", index=False)\n",
    "    error_train = sklearn.metrics.mean_absolute_error(train_true,train_prdictions)\n",
    "\n",
    "    return error_train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.64055\tvalid_1's rmse: 3.69642\n",
      "[200]\ttraining's rmse: 3.63904\tvalid_1's rmse: 3.69647\n",
      "[300]\ttraining's rmse: 3.63832\tvalid_1's rmse: 3.69576\n",
      "[400]\ttraining's rmse: 3.63792\tvalid_1's rmse: 3.69546\n",
      "[500]\ttraining's rmse: 3.63579\tvalid_1's rmse: 3.69447\n",
      "[600]\ttraining's rmse: 3.63604\tvalid_1's rmse: 3.69506\n",
      "[700]\ttraining's rmse: 3.6354\tvalid_1's rmse: 3.69447\n",
      "[800]\ttraining's rmse: 3.63619\tvalid_1's rmse: 3.69484\n",
      "[900]\ttraining's rmse: 3.63511\tvalid_1's rmse: 3.69357\n",
      "[1000]\ttraining's rmse: 3.63573\tvalid_1's rmse: 3.69418\n",
      "[1100]\ttraining's rmse: 3.63608\tvalid_1's rmse: 3.69437\n",
      "[1200]\ttraining's rmse: 3.63492\tvalid_1's rmse: 3.69238\n",
      "Early stopping, best iteration is:\n",
      "[1008]\ttraining's rmse: 3.63403\tvalid_1's rmse: 3.69287\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65866\tvalid_1's rmse: 3.63037\n",
      "[200]\ttraining's rmse: 3.65331\tvalid_1's rmse: 3.62731\n",
      "[300]\ttraining's rmse: 3.65155\tvalid_1's rmse: 3.62695\n",
      "[400]\ttraining's rmse: 3.65047\tvalid_1's rmse: 3.62707\n",
      "[500]\ttraining's rmse: 3.65047\tvalid_1's rmse: 3.62739\n",
      "[600]\ttraining's rmse: 3.65075\tvalid_1's rmse: 3.62767\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's rmse: 3.65015\tvalid_1's rmse: 3.62622\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65864\tvalid_1's rmse: 3.61631\n",
      "[200]\ttraining's rmse: 3.6577\tvalid_1's rmse: 3.6134\n",
      "[300]\ttraining's rmse: 3.65653\tvalid_1's rmse: 3.61188\n",
      "[400]\ttraining's rmse: 3.65479\tvalid_1's rmse: 3.61156\n",
      "[500]\ttraining's rmse: 3.65401\tvalid_1's rmse: 3.61081\n",
      "[600]\ttraining's rmse: 3.65437\tvalid_1's rmse: 3.6114\n",
      "[700]\ttraining's rmse: 3.65344\tvalid_1's rmse: 3.61078\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's rmse: 3.65306\tvalid_1's rmse: 3.61059\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.61302\tvalid_1's rmse: 3.8081\n",
      "[200]\ttraining's rmse: 3.60934\tvalid_1's rmse: 3.80672\n",
      "[300]\ttraining's rmse: 3.60814\tvalid_1's rmse: 3.8037\n",
      "[400]\ttraining's rmse: 3.60741\tvalid_1's rmse: 3.80239\n",
      "[500]\ttraining's rmse: 3.60689\tvalid_1's rmse: 3.80139\n",
      "[600]\ttraining's rmse: 3.60592\tvalid_1's rmse: 3.8005\n",
      "[700]\ttraining's rmse: 3.60596\tvalid_1's rmse: 3.80049\n",
      "Early stopping, best iteration is:\n",
      "[576]\ttraining's rmse: 3.60553\tvalid_1's rmse: 3.80034\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65928\tvalid_1's rmse: 3.62973\n",
      "[200]\ttraining's rmse: 3.65662\tvalid_1's rmse: 3.62827\n",
      "[300]\ttraining's rmse: 3.65327\tvalid_1's rmse: 3.62641\n",
      "[400]\ttraining's rmse: 3.65197\tvalid_1's rmse: 3.6264\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's rmse: 3.65276\tvalid_1's rmse: 3.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-02-15 22:14:36,953] Finished a trial resulted in value: 1.5524799357442964. Current best value is 1.5524799357442964 with parameters: {'learning_rate': 0.6129707926958924, 'top_rate': 0.6351386486354692, 'min_child_weight': 271, 'other_rate': 0.6996507555220448, 'num_leaves': 476, 'min_gain_split': 366.56499230255895, 'reg_lambda': 222.92932996562237, 'sub_sample': 0.08474710317963396, 'colsample_bytree_tuna': 0.9520231859522077, 'max_depth': 19}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.22484\tvalid_1's rmse: 3.71035\n",
      "[200]\ttraining's rmse: 3.2319\tvalid_1's rmse: 3.69983\n",
      "[300]\ttraining's rmse: 3.24343\tvalid_1's rmse: 3.69469\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 3.20886\tvalid_1's rmse: 3.70984\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.23056\tvalid_1's rmse: 3.63265\n",
      "[200]\ttraining's rmse: 3.24715\tvalid_1's rmse: 3.62315\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's rmse: 3.2259\tvalid_1's rmse: 3.63392\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.24867\tvalid_1's rmse: 3.62312\n",
      "[200]\ttraining's rmse: 3.2729\tvalid_1's rmse: 3.6127\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's rmse: 3.24276\tvalid_1's rmse: 3.62634\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.22306\tvalid_1's rmse: 3.81066\n",
      "[200]\ttraining's rmse: 3.2275\tvalid_1's rmse: 3.80315\n",
      "[300]\ttraining's rmse: 3.24034\tvalid_1's rmse: 3.79523\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 3.21713\tvalid_1's rmse: 3.80559\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.2459\tvalid_1's rmse: 3.64229\n",
      "[200]\ttraining's rmse: 3.25611\tvalid_1's rmse: 3.63533\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's rmse: 3.23939\tvalid_1's rmse: 3.64544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-02-16 02:17:53,825] Finished a trial resulted in value: 1.4503054340278518. Current best value is 1.4503054340278518 with parameters: {'learning_rate': 0.6467720115100732, 'top_rate': 0.7790255922489042, 'min_child_weight': 85, 'other_rate': 0.05539729354616829, 'num_leaves': 987, 'min_gain_split': 41.836633393708205, 'reg_lambda': 246.1691414168485, 'sub_sample': 0.4087483998244248, 'colsample_bytree_tuna': 0.5331266981851617, 'max_depth': 57}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.49874\tvalid_1's rmse: 3.68305\n",
      "[200]\ttraining's rmse: 3.5026\tvalid_1's rmse: 3.67887\n",
      "[300]\ttraining's rmse: 3.49458\tvalid_1's rmse: 3.67675\n",
      "[400]\ttraining's rmse: 3.49169\tvalid_1's rmse: 3.6776\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's rmse: 3.49449\tvalid_1's rmse: 3.6765\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.50797\tvalid_1's rmse: 3.61887\n",
      "[200]\ttraining's rmse: 3.50709\tvalid_1's rmse: 3.61845\n",
      "[300]\ttraining's rmse: 3.50396\tvalid_1's rmse: 3.61871\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's rmse: 3.5069\tvalid_1's rmse: 3.61581\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.52014\tvalid_1's rmse: 3.60555\n",
      "[200]\ttraining's rmse: 3.51414\tvalid_1's rmse: 3.60411\n",
      "[300]\ttraining's rmse: 3.51538\tvalid_1's rmse: 3.60137\n",
      "[400]\ttraining's rmse: 3.5117\tvalid_1's rmse: 3.60066\n",
      "[500]\ttraining's rmse: 3.51126\tvalid_1's rmse: 3.59911\n",
      "Early stopping, best iteration is:\n",
      "[335]\ttraining's rmse: 3.5091\tvalid_1's rmse: 3.60026\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.47007\tvalid_1's rmse: 3.78994\n",
      "[200]\ttraining's rmse: 3.46532\tvalid_1's rmse: 3.78618\n",
      "[300]\ttraining's rmse: 3.46724\tvalid_1's rmse: 3.78417\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's rmse: 3.46457\tvalid_1's rmse: 3.78638\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.51726\tvalid_1's rmse: 3.61666\n",
      "[200]\ttraining's rmse: 3.51277\tvalid_1's rmse: 3.61116\n",
      "[300]\ttraining's rmse: 3.51036\tvalid_1's rmse: 3.61084\n",
      "[400]\ttraining's rmse: 3.50425\tvalid_1's rmse: 3.61126\n",
      "[500]\ttraining's rmse: 3.50613\tvalid_1's rmse: 3.61057\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(kfold_lightgbm, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df=pd.read_csv(\"../output/feature_importance.csv\")\n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree_tuna': 0.83435723889734326,\n",
       " 'learning_rate': 0.75836372582243783,\n",
       " 'max_depth': 29,\n",
       " 'min_child_weight': 27,\n",
       " 'min_gain_split': 27.378180277455101,\n",
       " 'num_leaves': 562,\n",
       " 'other_rate': 0.03564199289369395,\n",
       " 'reg_lambda': 94.549009291544877,\n",
       " 'sub_sample': 0.91158142068248083,\n",
       " 'top_rate': 0.72876375065913579}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "sub_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"../output/submit_lgb\"+str(n)+\"_optuna.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
