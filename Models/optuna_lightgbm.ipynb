{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naoki Tomita\\Desktop\\kaggle_elo\\Models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import gc \n",
    "import time\n",
    "import optuna\n",
    "\n",
    "plt.style.use('ggplot') # Lets make our plots pretty\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'first_active_month', 'card_id', 'feature_1', 'feature_2',\n",
      "       'feature_3', 'target', 'elapsed_time', 'outliers',\n",
      "       'hist_transactions_count',\n",
      "       ...\n",
      "       'installments_purchase_amount_max', 'installments_purchase_amount_std',\n",
      "       'city_id_purchase_amount_mean', 'city_id_purchase_amount_min',\n",
      "       'city_id_purchase_amount_max', 'city_id_purchase_amount_std',\n",
      "       'category_1_installments_mean', 'category_1_installments_min',\n",
      "       'category_1_installments_max', 'category_1_installments_std'],\n",
      "      dtype='object', length=226)\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataframes\n",
    "train = pd.read_csv('../input/train_1.csv')\n",
    "test = pd.read_csv('../input/test_1.csv')\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "target = train['target']\n",
    "del train['target']\n",
    "#del train['outliners']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_lightgbm(trial):\n",
    "    FEATS_EXCLUDED = ['first_active_month', 'target', 'card_id', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "                  'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size',\n",
    "                  'OOF_PRED', 'month_0']\n",
    "    seed=20190208\n",
    "        \n",
    "    # params optimized by optuna\n",
    "    learning_rate_tuna = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    toprate_tuna = trial.suggest_uniform('top_rate', 0, 1.0)\n",
    "    num_leaves_tuna = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    min_child_weight_tuna = trial.suggest_int('min_child_weight', 5, 500)\n",
    "    other_rate_tuna=trial.suggest_uniform('other_rate', 0.0, 1.0)\n",
    "    num_leaves_tuna=trial.suggest_int('num_leaves', 5, 1000)\n",
    "    min_gain_split_tuna=trial.suggest_uniform('min_gain_split', 5, 500)\n",
    "    reg_lambda_tuna=trial.suggest_uniform('reg_lambda', 5, 500)\n",
    "        \n",
    "    param ={'task': 'train',\n",
    "            'boosting': 'dart',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': learning_rate_tuna ,\n",
    "            'subsample': 0.9855232997390695,\n",
    "            'max_depth': 7,\n",
    "            'top_rate': toprate_tuna ,\n",
    "            'num_leaves': num_leaves_tuna,\n",
    "            'min_child_weight': min_child_weight_tuna,\n",
    "            'other_rate': other_rate_tuna,\n",
    "            'reg_alpha': 9.677537745007898,\n",
    "            'colsample_bytree': 0.5665320670155495,\n",
    "            'min_split_gain': min_gain_split_tuna,\n",
    "            'reg_lambda': reg_lambda_tuna,\n",
    "            'min_data_in_leaf': 21,\n",
    "            'verbose': -1,\n",
    "            'seed':seed,\n",
    "            'bagging_seed':seed,\n",
    "            'drop_seed':seed,\n",
    "            'max_bin':255,\n",
    "            'device':'gpu'\n",
    "            }\n",
    "\n",
    "    # Create arrays and dataframes to store results\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "                  \n",
    "    # k-fold\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    sub_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "    sub_df[\"target\"] = predictions\n",
    "    sub_df.to_csv(\"submit_lgb\"+str(n)+\"_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1194: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:753: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n",
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\callback.py:189: UserWarning: Early stopping is not available in dart mode\n",
      "  warnings.warn('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 1.72592\tvalid_1's rmse: 1.72472\n",
      "[200]\ttraining's rmse: 1.57719\tvalid_1's rmse: 1.57223\n",
      "[300]\ttraining's rmse: 1.57978\tvalid_1's rmse: 1.57436\n",
      "[400]\ttraining's rmse: 1.56544\tvalid_1's rmse: 1.55929\n",
      "[500]\ttraining's rmse: 1.56402\tvalid_1's rmse: 1.55762\n",
      "[600]\ttraining's rmse: 1.56403\tvalid_1's rmse: 1.55753\n",
      "[700]\ttraining's rmse: 1.56785\tvalid_1's rmse: 1.56116\n",
      "[800]\ttraining's rmse: 1.56378\tvalid_1's rmse: 1.55673\n",
      "[900]\ttraining's rmse: 1.56465\tvalid_1's rmse: 1.55752\n",
      "[1000]\ttraining's rmse: 1.56393\tvalid_1's rmse: 1.55671\n",
      "[1100]\ttraining's rmse: 1.56438\tvalid_1's rmse: 1.55713\n",
      "[1200]\ttraining's rmse: 1.56431\tvalid_1's rmse: 1.55688\n",
      "[1300]\ttraining's rmse: 1.56422\tvalid_1's rmse: 1.55687\n",
      "[1400]\ttraining's rmse: 1.56396\tvalid_1's rmse: 1.55646\n",
      "[1500]\ttraining's rmse: 1.56441\tvalid_1's rmse: 1.55681\n",
      "[1600]\ttraining's rmse: 1.56482\tvalid_1's rmse: 1.55704\n",
      "[1700]\ttraining's rmse: 1.56446\tvalid_1's rmse: 1.55662\n",
      "[1800]\ttraining's rmse: 1.56448\tvalid_1's rmse: 1.55673\n",
      "[1900]\ttraining's rmse: 1.5648\tvalid_1's rmse: 1.557\n",
      "[2000]\ttraining's rmse: 1.56489\tvalid_1's rmse: 1.55703\n",
      "[2100]\ttraining's rmse: 1.56532\tvalid_1's rmse: 1.55743\n",
      "[2200]\ttraining's rmse: 1.56516\tvalid_1's rmse: 1.55719\n",
      "[2300]\ttraining's rmse: 1.56553\tvalid_1's rmse: 1.55745\n",
      "[2400]\ttraining's rmse: 1.56552\tvalid_1's rmse: 1.55744\n",
      "[2500]\ttraining's rmse: 1.56528\tvalid_1's rmse: 1.5572\n",
      "[2600]\ttraining's rmse: 1.56546\tvalid_1's rmse: 1.55739\n",
      "[2700]\ttraining's rmse: 1.56562\tvalid_1's rmse: 1.55756\n",
      "[2800]\ttraining's rmse: 1.56572\tvalid_1's rmse: 1.55754\n",
      "[2900]\ttraining's rmse: 1.5659\tvalid_1's rmse: 1.5577\n",
      "[3000]\ttraining's rmse: 1.56602\tvalid_1's rmse: 1.55779\n",
      "[3100]\ttraining's rmse: 1.56619\tvalid_1's rmse: 1.55796\n",
      "[3200]\ttraining's rmse: 1.56605\tvalid_1's rmse: 1.55775\n",
      "[3300]\ttraining's rmse: 1.56614\tvalid_1's rmse: 1.5578\n",
      "[3400]\ttraining's rmse: 1.56603\tvalid_1's rmse: 1.55774\n",
      "[3500]\ttraining's rmse: 1.56605\tvalid_1's rmse: 1.55771\n",
      "[3600]\ttraining's rmse: 1.56607\tvalid_1's rmse: 1.55786\n",
      "[3700]\ttraining's rmse: 1.5662\tvalid_1's rmse: 1.5579\n",
      "[3800]\ttraining's rmse: 1.56635\tvalid_1's rmse: 1.55801\n",
      "[3900]\ttraining's rmse: 1.56628\tvalid_1's rmse: 1.55795\n",
      "[4000]\ttraining's rmse: 1.56617\tvalid_1's rmse: 1.5578\n",
      "[4100]\ttraining's rmse: 1.56633\tvalid_1's rmse: 1.5579\n",
      "[4200]\ttraining's rmse: 1.56648\tvalid_1's rmse: 1.55803\n",
      "[4300]\ttraining's rmse: 1.56645\tvalid_1's rmse: 1.5581\n",
      "[4400]\ttraining's rmse: 1.56651\tvalid_1's rmse: 1.55813\n",
      "[4500]\ttraining's rmse: 1.56649\tvalid_1's rmse: 1.55808\n",
      "[4600]\ttraining's rmse: 1.56654\tvalid_1's rmse: 1.55807\n",
      "[4700]\ttraining's rmse: 1.56653\tvalid_1's rmse: 1.55808\n",
      "[4800]\ttraining's rmse: 1.56661\tvalid_1's rmse: 1.55817\n",
      "[4900]\ttraining's rmse: 1.56665\tvalid_1's rmse: 1.55813\n",
      "[5000]\ttraining's rmse: 1.56662\tvalid_1's rmse: 1.55813\n",
      "[5100]\ttraining's rmse: 1.56676\tvalid_1's rmse: 1.55826\n",
      "[5200]\ttraining's rmse: 1.56675\tvalid_1's rmse: 1.55827\n",
      "[5300]\ttraining's rmse: 1.56664\tvalid_1's rmse: 1.55812\n",
      "[5400]\ttraining's rmse: 1.56667\tvalid_1's rmse: 1.55812\n",
      "[5500]\ttraining's rmse: 1.56674\tvalid_1's rmse: 1.55816\n",
      "[5600]\ttraining's rmse: 1.56688\tvalid_1's rmse: 1.55824\n",
      "[5700]\ttraining's rmse: 1.56673\tvalid_1's rmse: 1.5582\n",
      "[5800]\ttraining's rmse: 1.56664\tvalid_1's rmse: 1.55807\n",
      "[5900]\ttraining's rmse: 1.56674\tvalid_1's rmse: 1.55779\n",
      "[6000]\ttraining's rmse: 1.56696\tvalid_1's rmse: 1.55789\n",
      "[6100]\ttraining's rmse: 1.56679\tvalid_1's rmse: 1.55782\n",
      "[6200]\ttraining's rmse: 1.56691\tvalid_1's rmse: 1.55793\n",
      "[6300]\ttraining's rmse: 1.56688\tvalid_1's rmse: 1.55788\n",
      "[6400]\ttraining's rmse: 1.56691\tvalid_1's rmse: 1.55798\n",
      "[6500]\ttraining's rmse: 1.56707\tvalid_1's rmse: 1.55806\n",
      "[6600]\ttraining's rmse: 1.56716\tvalid_1's rmse: 1.55814\n",
      "[6700]\ttraining's rmse: 1.56721\tvalid_1's rmse: 1.55818\n",
      "[6800]\ttraining's rmse: 1.5674\tvalid_1's rmse: 1.5585\n",
      "[6900]\ttraining's rmse: 1.56737\tvalid_1's rmse: 1.55845\n",
      "[7000]\ttraining's rmse: 1.56735\tvalid_1's rmse: 1.55848\n",
      "[7100]\ttraining's rmse: 1.56731\tvalid_1's rmse: 1.55848\n",
      "[7200]\ttraining's rmse: 1.56743\tvalid_1's rmse: 1.55924\n",
      "[7300]\ttraining's rmse: 1.56738\tvalid_1's rmse: 1.55975\n",
      "[7400]\ttraining's rmse: 1.56737\tvalid_1's rmse: 1.56068\n",
      "[7500]\ttraining's rmse: 1.56748\tvalid_1's rmse: 1.56067\n",
      "[7600]\ttraining's rmse: 1.56754\tvalid_1's rmse: 1.56053\n",
      "[7700]\ttraining's rmse: 1.56753\tvalid_1's rmse: 1.56083\n",
      "[7800]\ttraining's rmse: 1.56758\tvalid_1's rmse: 1.5607\n",
      "[7900]\ttraining's rmse: 1.56742\tvalid_1's rmse: 1.56075\n",
      "[8000]\ttraining's rmse: 1.56751\tvalid_1's rmse: 1.56081\n",
      "[8100]\ttraining's rmse: 1.56739\tvalid_1's rmse: 1.56063\n",
      "[8200]\ttraining's rmse: 1.56744\tvalid_1's rmse: 1.56079\n",
      "[8300]\ttraining's rmse: 1.56742\tvalid_1's rmse: 1.56065\n",
      "[8400]\ttraining's rmse: 1.56749\tvalid_1's rmse: 1.56054\n",
      "[8500]\ttraining's rmse: 1.5675\tvalid_1's rmse: 1.56283\n",
      "[8600]\ttraining's rmse: 1.56756\tvalid_1's rmse: 1.56365\n",
      "[8700]\ttraining's rmse: 1.56771\tvalid_1's rmse: 1.56406\n",
      "[8800]\ttraining's rmse: 1.56774\tvalid_1's rmse: 1.56548\n",
      "[8900]\ttraining's rmse: 1.56776\tvalid_1's rmse: 1.5655\n",
      "[9000]\ttraining's rmse: 1.56787\tvalid_1's rmse: 1.56717\n",
      "[9100]\ttraining's rmse: 1.56786\tvalid_1's rmse: 1.56751\n",
      "[9200]\ttraining's rmse: 1.56797\tvalid_1's rmse: 1.56986\n",
      "[9300]\ttraining's rmse: 1.56801\tvalid_1's rmse: 1.57178\n",
      "[9400]\ttraining's rmse: 1.56811\tvalid_1's rmse: 1.57408\n",
      "[9500]\ttraining's rmse: 1.56806\tvalid_1's rmse: 1.57458\n",
      "[9600]\ttraining's rmse: 1.56811\tvalid_1's rmse: 1.57747\n",
      "[9700]\ttraining's rmse: 1.56821\tvalid_1's rmse: 1.57818\n",
      "[9800]\ttraining's rmse: 1.56828\tvalid_1's rmse: 1.57854\n",
      "[9900]\ttraining's rmse: 1.56825\tvalid_1's rmse: 1.58284\n",
      "[10000]\ttraining's rmse: 1.56829\tvalid_1's rmse: 1.58289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:12:47,053] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.57065\tvalid_1's rmse: 1.56055\n",
      "[200]\ttraining's rmse: 1.57213\tvalid_1's rmse: 1.56148\n",
      "[300]\ttraining's rmse: 1.57365\tvalid_1's rmse: 1.5634\n",
      "[400]\ttraining's rmse: 1.5728\tvalid_1's rmse: 1.56246\n",
      "[500]\ttraining's rmse: 1.57241\tvalid_1's rmse: 1.56186\n",
      "[600]\ttraining's rmse: 1.5729\tvalid_1's rmse: 1.56259\n",
      "[700]\ttraining's rmse: 1.57079\tvalid_1's rmse: 1.56111\n",
      "[800]\ttraining's rmse: 1.57221\tvalid_1's rmse: 1.56223\n",
      "[900]\ttraining's rmse: 1.57178\tvalid_1's rmse: 1.56185\n",
      "[1000]\ttraining's rmse: 1.5723\tvalid_1's rmse: 1.56247\n",
      "[1100]\ttraining's rmse: 1.57207\tvalid_1's rmse: 1.56213\n",
      "[1200]\ttraining's rmse: 1.57198\tvalid_1's rmse: 1.56191\n",
      "[1300]\ttraining's rmse: 1.57181\tvalid_1's rmse: 1.5615\n",
      "[1400]\ttraining's rmse: 1.57209\tvalid_1's rmse: 1.56211\n",
      "[1500]\ttraining's rmse: 1.57118\tvalid_1's rmse: 1.56148\n",
      "[1600]\ttraining's rmse: 1.57218\tvalid_1's rmse: 1.56228\n",
      "[1700]\ttraining's rmse: 1.5722\tvalid_1's rmse: 1.56232\n",
      "[1800]\ttraining's rmse: 1.57176\tvalid_1's rmse: 1.56189\n",
      "[1900]\ttraining's rmse: 1.57193\tvalid_1's rmse: 1.56189\n",
      "[2000]\ttraining's rmse: 1.57229\tvalid_1's rmse: 1.56214\n",
      "[2100]\ttraining's rmse: 1.57108\tvalid_1's rmse: 1.56768\n",
      "[2200]\ttraining's rmse: 1.5715\tvalid_1's rmse: 1.56819\n",
      "[2300]\ttraining's rmse: 1.57229\tvalid_1's rmse: 1.57691\n",
      "[2400]\ttraining's rmse: 1.57252\tvalid_1's rmse: 1.57748\n",
      "[2500]\ttraining's rmse: 1.57311\tvalid_1's rmse: 1.5759\n",
      "[2600]\ttraining's rmse: 1.57234\tvalid_1's rmse: 1.57636\n",
      "[2700]\ttraining's rmse: 1.57208\tvalid_1's rmse: 1.58481\n",
      "[2800]\ttraining's rmse: 1.57346\tvalid_1's rmse: 1.64494\n",
      "[2900]\ttraining's rmse: 1.57391\tvalid_1's rmse: 1.66861\n",
      "[3000]\ttraining's rmse: 1.57378\tvalid_1's rmse: 1.67502\n",
      "[3100]\ttraining's rmse: 1.57406\tvalid_1's rmse: 1.67496\n",
      "[3200]\ttraining's rmse: 1.57354\tvalid_1's rmse: 1.70295\n",
      "[3300]\ttraining's rmse: 1.57398\tvalid_1's rmse: 1.75628\n",
      "[3400]\ttraining's rmse: 1.5733\tvalid_1's rmse: 1.77916\n",
      "[3500]\ttraining's rmse: 1.5737\tvalid_1's rmse: 1.78314\n",
      "[3600]\ttraining's rmse: 1.57304\tvalid_1's rmse: 1.79378\n",
      "[3700]\ttraining's rmse: 1.57338\tvalid_1's rmse: 1.82904\n",
      "[3800]\ttraining's rmse: 1.57414\tvalid_1's rmse: 1.81705\n",
      "[3900]\ttraining's rmse: 1.57544\tvalid_1's rmse: 1.89689\n",
      "[4000]\ttraining's rmse: 1.5735\tvalid_1's rmse: 2.00704\n",
      "[4100]\ttraining's rmse: 1.57288\tvalid_1's rmse: 2.03663\n",
      "[4200]\ttraining's rmse: 1.5738\tvalid_1's rmse: 2.07571\n",
      "[4300]\ttraining's rmse: 1.57386\tvalid_1's rmse: 2.08539\n",
      "[4400]\ttraining's rmse: 1.57286\tvalid_1's rmse: 2.11401\n",
      "[4500]\ttraining's rmse: 1.57252\tvalid_1's rmse: 2.09263\n",
      "[4600]\ttraining's rmse: 1.57221\tvalid_1's rmse: 2.09108\n",
      "[4700]\ttraining's rmse: 1.57214\tvalid_1's rmse: 2.10141\n",
      "[4800]\ttraining's rmse: 1.57219\tvalid_1's rmse: 2.12595\n",
      "[4900]\ttraining's rmse: 1.57128\tvalid_1's rmse: 2.14509\n",
      "[5000]\ttraining's rmse: 1.57063\tvalid_1's rmse: 2.14268\n",
      "[5100]\ttraining's rmse: 1.57068\tvalid_1's rmse: 2.19482\n",
      "[5200]\ttraining's rmse: 1.5712\tvalid_1's rmse: 2.22947\n",
      "[5300]\ttraining's rmse: 1.57063\tvalid_1's rmse: 2.22899\n",
      "[5400]\ttraining's rmse: 1.57075\tvalid_1's rmse: 2.20818\n",
      "[5500]\ttraining's rmse: 1.5709\tvalid_1's rmse: 2.16255\n",
      "[5600]\ttraining's rmse: 1.57154\tvalid_1's rmse: 2.21752\n",
      "[5700]\ttraining's rmse: 1.57093\tvalid_1's rmse: 2.2635\n",
      "[5800]\ttraining's rmse: 1.57138\tvalid_1's rmse: 2.28338\n",
      "[5900]\ttraining's rmse: 1.57099\tvalid_1's rmse: 2.25917\n",
      "[6000]\ttraining's rmse: 1.57112\tvalid_1's rmse: 2.33003\n",
      "[6100]\ttraining's rmse: 1.57136\tvalid_1's rmse: 2.30701\n",
      "[6200]\ttraining's rmse: 1.57057\tvalid_1's rmse: 2.26477\n",
      "[6300]\ttraining's rmse: 1.57141\tvalid_1's rmse: 2.30786\n",
      "[6400]\ttraining's rmse: 1.5718\tvalid_1's rmse: 2.32517\n",
      "[6500]\ttraining's rmse: 1.57197\tvalid_1's rmse: 2.30914\n",
      "[6600]\ttraining's rmse: 1.57166\tvalid_1's rmse: 2.32058\n",
      "[6700]\ttraining's rmse: 1.57113\tvalid_1's rmse: 2.37061\n",
      "[6800]\ttraining's rmse: 1.57126\tvalid_1's rmse: 2.3999\n",
      "[6900]\ttraining's rmse: 1.57124\tvalid_1's rmse: 2.38001\n",
      "[7000]\ttraining's rmse: 1.57185\tvalid_1's rmse: 2.37783\n",
      "[7100]\ttraining's rmse: 1.57072\tvalid_1's rmse: 2.37696\n",
      "[7200]\ttraining's rmse: 1.57108\tvalid_1's rmse: 2.3888\n",
      "[7300]\ttraining's rmse: 1.57107\tvalid_1's rmse: 2.40384\n",
      "[7400]\ttraining's rmse: 1.57087\tvalid_1's rmse: 2.38346\n",
      "[7500]\ttraining's rmse: 1.57093\tvalid_1's rmse: 2.3883\n",
      "[7600]\ttraining's rmse: 1.57105\tvalid_1's rmse: 2.41835\n",
      "[7700]\ttraining's rmse: 1.57104\tvalid_1's rmse: 2.42823\n",
      "[7800]\ttraining's rmse: 1.57074\tvalid_1's rmse: 2.40028\n",
      "[7900]\ttraining's rmse: 1.57144\tvalid_1's rmse: 2.43695\n",
      "[8000]\ttraining's rmse: 1.57012\tvalid_1's rmse: 2.45418\n",
      "[8100]\ttraining's rmse: 1.57042\tvalid_1's rmse: 2.45397\n",
      "[8200]\ttraining's rmse: 1.57082\tvalid_1's rmse: 2.45318\n",
      "[8300]\ttraining's rmse: 1.57012\tvalid_1's rmse: 2.46847\n",
      "[8400]\ttraining's rmse: 1.57063\tvalid_1's rmse: 2.45704\n",
      "[8500]\ttraining's rmse: 1.57077\tvalid_1's rmse: 2.457\n",
      "[8600]\ttraining's rmse: 1.57067\tvalid_1's rmse: 2.48354\n",
      "[8700]\ttraining's rmse: 1.57056\tvalid_1's rmse: 2.49054\n",
      "[8800]\ttraining's rmse: 1.5703\tvalid_1's rmse: 2.55325\n",
      "[8900]\ttraining's rmse: 1.5703\tvalid_1's rmse: 2.56716\n",
      "[9000]\ttraining's rmse: 1.56996\tvalid_1's rmse: 2.51511\n",
      "[9100]\ttraining's rmse: 1.56994\tvalid_1's rmse: 2.51558\n",
      "[9200]\ttraining's rmse: 1.57028\tvalid_1's rmse: 2.51776\n",
      "[9300]\ttraining's rmse: 1.57056\tvalid_1's rmse: 2.55196\n",
      "[9400]\ttraining's rmse: 1.57021\tvalid_1's rmse: 2.5678\n",
      "[9500]\ttraining's rmse: 1.57015\tvalid_1's rmse: 2.56949\n",
      "[9600]\ttraining's rmse: 1.57055\tvalid_1's rmse: 2.57071\n",
      "[9700]\ttraining's rmse: 1.56999\tvalid_1's rmse: 2.56998\n",
      "[9800]\ttraining's rmse: 1.57042\tvalid_1's rmse: 2.56664\n",
      "[9900]\ttraining's rmse: 1.57058\tvalid_1's rmse: 2.5867\n",
      "[10000]\ttraining's rmse: 1.57023\tvalid_1's rmse: 2.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:16:48,753] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.57613\tvalid_1's rmse: 1.56675\n",
      "[200]\ttraining's rmse: 1.57215\tvalid_1's rmse: 1.56239\n",
      "[300]\ttraining's rmse: 1.5724\tvalid_1's rmse: 1.56267\n",
      "[400]\ttraining's rmse: 1.57269\tvalid_1's rmse: 1.563\n",
      "[500]\ttraining's rmse: 1.5731\tvalid_1's rmse: 1.56334\n",
      "[600]\ttraining's rmse: 1.57388\tvalid_1's rmse: 1.56429\n",
      "[700]\ttraining's rmse: 1.57348\tvalid_1's rmse: 1.56373\n",
      "[800]\ttraining's rmse: 1.57312\tvalid_1's rmse: 1.56362\n",
      "[900]\ttraining's rmse: 1.57271\tvalid_1's rmse: 1.56296\n",
      "[1000]\ttraining's rmse: 1.57314\tvalid_1's rmse: 1.56339\n",
      "[1100]\ttraining's rmse: 1.57293\tvalid_1's rmse: 1.5631\n",
      "[1200]\ttraining's rmse: 1.57287\tvalid_1's rmse: 1.56322\n",
      "[1300]\ttraining's rmse: 1.57219\tvalid_1's rmse: 1.56273\n",
      "[1400]\ttraining's rmse: 1.57212\tvalid_1's rmse: 1.56248\n",
      "[1500]\ttraining's rmse: 1.57276\tvalid_1's rmse: 1.56292\n",
      "[1600]\ttraining's rmse: 1.57263\tvalid_1's rmse: 1.56292\n",
      "[1700]\ttraining's rmse: 1.57254\tvalid_1's rmse: 1.56295\n",
      "[1800]\ttraining's rmse: 1.57326\tvalid_1's rmse: 1.56343\n",
      "[1900]\ttraining's rmse: 1.57344\tvalid_1's rmse: 1.56344\n",
      "[2000]\ttraining's rmse: 1.57334\tvalid_1's rmse: 1.5635\n",
      "[2100]\ttraining's rmse: 1.57339\tvalid_1's rmse: 1.56336\n",
      "[2200]\ttraining's rmse: 1.57336\tvalid_1's rmse: 1.56334\n",
      "[2300]\ttraining's rmse: 1.57364\tvalid_1's rmse: 1.56358\n",
      "[2400]\ttraining's rmse: 1.57316\tvalid_1's rmse: 1.56322\n",
      "[2500]\ttraining's rmse: 1.57375\tvalid_1's rmse: 1.56368\n",
      "[2600]\ttraining's rmse: 1.57369\tvalid_1's rmse: 1.56371\n",
      "[2700]\ttraining's rmse: 1.57405\tvalid_1's rmse: 1.56395\n",
      "[2800]\ttraining's rmse: 1.57416\tvalid_1's rmse: 1.56398\n",
      "[2900]\ttraining's rmse: 1.57411\tvalid_1's rmse: 1.56333\n",
      "[3000]\ttraining's rmse: 1.57415\tvalid_1's rmse: 1.56373\n",
      "[3100]\ttraining's rmse: 1.57467\tvalid_1's rmse: 1.56351\n",
      "[3200]\ttraining's rmse: 1.57599\tvalid_1's rmse: 1.56494\n",
      "[3300]\ttraining's rmse: 1.57331\tvalid_1's rmse: 1.56703\n",
      "[3400]\ttraining's rmse: 1.5734\tvalid_1's rmse: 1.57589\n",
      "[3500]\ttraining's rmse: 1.57379\tvalid_1's rmse: 1.5826\n",
      "[3600]\ttraining's rmse: 1.57399\tvalid_1's rmse: 1.58252\n",
      "[3700]\ttraining's rmse: 1.57385\tvalid_1's rmse: 1.58717\n",
      "[3800]\ttraining's rmse: 1.57413\tvalid_1's rmse: 1.62954\n",
      "[3900]\ttraining's rmse: 1.5742\tvalid_1's rmse: 1.65774\n",
      "[4000]\ttraining's rmse: 1.57427\tvalid_1's rmse: 1.67225\n",
      "[4100]\ttraining's rmse: 1.57464\tvalid_1's rmse: 1.66936\n",
      "[4200]\ttraining's rmse: 1.57445\tvalid_1's rmse: 1.69603\n",
      "[4300]\ttraining's rmse: 1.57479\tvalid_1's rmse: 1.72189\n",
      "[4400]\ttraining's rmse: 1.57422\tvalid_1's rmse: 1.79966\n",
      "[4500]\ttraining's rmse: 1.57469\tvalid_1's rmse: 1.81233\n",
      "[4600]\ttraining's rmse: 1.575\tvalid_1's rmse: 1.83911\n",
      "[4700]\ttraining's rmse: 1.57534\tvalid_1's rmse: 1.86107\n",
      "[4800]\ttraining's rmse: 1.57503\tvalid_1's rmse: 1.88482\n",
      "[4900]\ttraining's rmse: 1.57487\tvalid_1's rmse: 1.90988\n",
      "[5000]\ttraining's rmse: 1.57501\tvalid_1's rmse: 1.93271\n",
      "[5100]\ttraining's rmse: 1.5747\tvalid_1's rmse: 1.92146\n",
      "[5200]\ttraining's rmse: 1.57518\tvalid_1's rmse: 1.93463\n",
      "[5300]\ttraining's rmse: 1.57461\tvalid_1's rmse: 1.9541\n",
      "[5400]\ttraining's rmse: 1.57481\tvalid_1's rmse: 1.95399\n",
      "[5500]\ttraining's rmse: 1.57462\tvalid_1's rmse: 1.9612\n",
      "[5600]\ttraining's rmse: 1.57565\tvalid_1's rmse: 1.95481\n",
      "[5700]\ttraining's rmse: 1.575\tvalid_1's rmse: 1.97798\n",
      "[5800]\ttraining's rmse: 1.57515\tvalid_1's rmse: 1.98527\n",
      "[5900]\ttraining's rmse: 1.57477\tvalid_1's rmse: 1.99334\n",
      "[6000]\ttraining's rmse: 1.57431\tvalid_1's rmse: 2.00772\n",
      "[6100]\ttraining's rmse: 1.5744\tvalid_1's rmse: 2.02509\n",
      "[6200]\ttraining's rmse: 1.57466\tvalid_1's rmse: 2.00936\n",
      "[6300]\ttraining's rmse: 1.57452\tvalid_1's rmse: 1.99056\n",
      "[6400]\ttraining's rmse: 1.57468\tvalid_1's rmse: 1.99038\n",
      "[6500]\ttraining's rmse: 1.57469\tvalid_1's rmse: 2.01571\n",
      "[6600]\ttraining's rmse: 1.57488\tvalid_1's rmse: 2.09122\n",
      "[6700]\ttraining's rmse: 1.57489\tvalid_1's rmse: 2.06482\n",
      "[6800]\ttraining's rmse: 1.57519\tvalid_1's rmse: 2.10818\n",
      "[6900]\ttraining's rmse: 1.57509\tvalid_1's rmse: 2.08825\n",
      "[7000]\ttraining's rmse: 1.57482\tvalid_1's rmse: 2.09299\n",
      "[7100]\ttraining's rmse: 1.57432\tvalid_1's rmse: 2.04048\n",
      "[7200]\ttraining's rmse: 1.57415\tvalid_1's rmse: 2.05177\n",
      "[7300]\ttraining's rmse: 1.57492\tvalid_1's rmse: 2.07156\n",
      "[7400]\ttraining's rmse: 1.57449\tvalid_1's rmse: 2.08656\n",
      "[7500]\ttraining's rmse: 1.57407\tvalid_1's rmse: 2.09025\n",
      "[7600]\ttraining's rmse: 1.57423\tvalid_1's rmse: 2.11456\n",
      "[7700]\ttraining's rmse: 1.5746\tvalid_1's rmse: 2.08113\n",
      "[7800]\ttraining's rmse: 1.57392\tvalid_1's rmse: 2.10631\n",
      "[7900]\ttraining's rmse: 1.57458\tvalid_1's rmse: 2.09208\n",
      "[8000]\ttraining's rmse: 1.57449\tvalid_1's rmse: 2.10099\n",
      "[8100]\ttraining's rmse: 1.57459\tvalid_1's rmse: 2.09977\n",
      "[8200]\ttraining's rmse: 1.5739\tvalid_1's rmse: 2.09832\n",
      "[8300]\ttraining's rmse: 1.57438\tvalid_1's rmse: 2.09688\n",
      "[8400]\ttraining's rmse: 1.57416\tvalid_1's rmse: 2.08516\n",
      "[8500]\ttraining's rmse: 1.57518\tvalid_1's rmse: 2.11645\n",
      "[8600]\ttraining's rmse: 1.57434\tvalid_1's rmse: 2.12632\n",
      "[8700]\ttraining's rmse: 1.57512\tvalid_1's rmse: 2.12481\n",
      "[8800]\ttraining's rmse: 1.57472\tvalid_1's rmse: 2.12367\n",
      "[8900]\ttraining's rmse: 1.57446\tvalid_1's rmse: 2.12272\n",
      "[9000]\ttraining's rmse: 1.57421\tvalid_1's rmse: 2.15328\n",
      "[9100]\ttraining's rmse: 1.57363\tvalid_1's rmse: 2.16621\n",
      "[9200]\ttraining's rmse: 1.57383\tvalid_1's rmse: 2.16534\n",
      "[9300]\ttraining's rmse: 1.57498\tvalid_1's rmse: 2.16483\n",
      "[9400]\ttraining's rmse: 1.57388\tvalid_1's rmse: 2.1836\n",
      "[9500]\ttraining's rmse: 1.57328\tvalid_1's rmse: 2.18394\n",
      "[9600]\ttraining's rmse: 1.57475\tvalid_1's rmse: 2.24473\n",
      "[9700]\ttraining's rmse: 1.57437\tvalid_1's rmse: 2.21667\n",
      "[9800]\ttraining's rmse: 1.57368\tvalid_1's rmse: 2.26696\n",
      "[9900]\ttraining's rmse: 1.57441\tvalid_1's rmse: 2.27075\n",
      "[10000]\ttraining's rmse: 1.5741\tvalid_1's rmse: 2.27471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:22:06,972] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.58778\tvalid_1's rmse: 1.58237\n",
      "[200]\ttraining's rmse: 1.56748\tvalid_1's rmse: 1.56096\n",
      "[300]\ttraining's rmse: 1.56397\tvalid_1's rmse: 1.55725\n",
      "[400]\ttraining's rmse: 1.56383\tvalid_1's rmse: 1.55677\n",
      "[500]\ttraining's rmse: 1.56383\tvalid_1's rmse: 1.55655\n",
      "[600]\ttraining's rmse: 1.56365\tvalid_1's rmse: 1.55618\n",
      "[700]\ttraining's rmse: 1.56478\tvalid_1's rmse: 1.55727\n",
      "[800]\ttraining's rmse: 1.56482\tvalid_1's rmse: 1.55739\n",
      "[900]\ttraining's rmse: 1.56402\tvalid_1's rmse: 1.55671\n",
      "[1000]\ttraining's rmse: 1.56476\tvalid_1's rmse: 1.55732\n",
      "[1100]\ttraining's rmse: 1.56418\tvalid_1's rmse: 1.55682\n",
      "[1200]\ttraining's rmse: 1.56439\tvalid_1's rmse: 1.55698\n",
      "[1300]\ttraining's rmse: 1.56479\tvalid_1's rmse: 1.5571\n",
      "[1400]\ttraining's rmse: 1.56478\tvalid_1's rmse: 1.55711\n",
      "[1500]\ttraining's rmse: 1.56473\tvalid_1's rmse: 1.55718\n",
      "[1600]\ttraining's rmse: 1.56465\tvalid_1's rmse: 1.55696\n",
      "[1700]\ttraining's rmse: 1.56503\tvalid_1's rmse: 1.55711\n",
      "[1800]\ttraining's rmse: 1.56493\tvalid_1's rmse: 1.55691\n",
      "[1900]\ttraining's rmse: 1.56519\tvalid_1's rmse: 1.55711\n",
      "[2000]\ttraining's rmse: 1.56559\tvalid_1's rmse: 1.55745\n",
      "[2100]\ttraining's rmse: 1.56501\tvalid_1's rmse: 1.55679\n",
      "[2200]\ttraining's rmse: 1.56515\tvalid_1's rmse: 1.55691\n",
      "[2300]\ttraining's rmse: 1.56551\tvalid_1's rmse: 1.5572\n",
      "[2400]\ttraining's rmse: 1.56534\tvalid_1's rmse: 1.55706\n",
      "[2500]\ttraining's rmse: 1.56579\tvalid_1's rmse: 1.55737\n",
      "[2600]\ttraining's rmse: 1.56557\tvalid_1's rmse: 1.5572\n",
      "[2700]\ttraining's rmse: 1.56576\tvalid_1's rmse: 1.55732\n",
      "[2800]\ttraining's rmse: 1.56576\tvalid_1's rmse: 1.55742\n",
      "[2900]\ttraining's rmse: 1.56559\tvalid_1's rmse: 1.55737\n",
      "[3000]\ttraining's rmse: 1.56576\tvalid_1's rmse: 1.55769\n",
      "[3100]\ttraining's rmse: 1.56561\tvalid_1's rmse: 1.55747\n",
      "[3200]\ttraining's rmse: 1.56595\tvalid_1's rmse: 1.55776\n",
      "[3300]\ttraining's rmse: 1.56597\tvalid_1's rmse: 1.55768\n",
      "[3400]\ttraining's rmse: 1.56609\tvalid_1's rmse: 1.55772\n",
      "[3500]\ttraining's rmse: 1.56624\tvalid_1's rmse: 1.55782\n",
      "[3600]\ttraining's rmse: 1.56637\tvalid_1's rmse: 1.55792\n",
      "[3700]\ttraining's rmse: 1.56641\tvalid_1's rmse: 1.55794\n",
      "[3800]\ttraining's rmse: 1.56597\tvalid_1's rmse: 1.55742\n",
      "[3900]\ttraining's rmse: 1.56622\tvalid_1's rmse: 1.55761\n",
      "[4000]\ttraining's rmse: 1.56597\tvalid_1's rmse: 1.55768\n",
      "[4100]\ttraining's rmse: 1.5667\tvalid_1's rmse: 1.55828\n",
      "[4200]\ttraining's rmse: 1.56562\tvalid_1's rmse: 1.55728\n",
      "[4300]\ttraining's rmse: 1.56598\tvalid_1's rmse: 1.55728\n",
      "[4400]\ttraining's rmse: 1.56628\tvalid_1's rmse: 1.55715\n",
      "[4500]\ttraining's rmse: 1.56646\tvalid_1's rmse: 1.55737\n",
      "[4600]\ttraining's rmse: 1.56597\tvalid_1's rmse: 1.55723\n",
      "[4700]\ttraining's rmse: 1.5662\tvalid_1's rmse: 1.5574\n",
      "[4800]\ttraining's rmse: 1.5662\tvalid_1's rmse: 1.55742\n",
      "[4900]\ttraining's rmse: 1.56655\tvalid_1's rmse: 1.55803\n",
      "[5000]\ttraining's rmse: 1.56638\tvalid_1's rmse: 1.56035\n",
      "[5100]\ttraining's rmse: 1.56657\tvalid_1's rmse: 1.56025\n",
      "[5200]\ttraining's rmse: 1.56652\tvalid_1's rmse: 1.56185\n",
      "[5300]\ttraining's rmse: 1.56671\tvalid_1's rmse: 1.56177\n",
      "[5400]\ttraining's rmse: 1.56688\tvalid_1's rmse: 1.56287\n",
      "[5500]\ttraining's rmse: 1.56693\tvalid_1's rmse: 1.56302\n",
      "[5600]\ttraining's rmse: 1.56678\tvalid_1's rmse: 1.56291\n",
      "[5700]\ttraining's rmse: 1.56672\tvalid_1's rmse: 1.56502\n",
      "[5800]\ttraining's rmse: 1.56683\tvalid_1's rmse: 1.56728\n",
      "[5900]\ttraining's rmse: 1.567\tvalid_1's rmse: 1.56662\n",
      "[6000]\ttraining's rmse: 1.56701\tvalid_1's rmse: 1.57285\n",
      "[6100]\ttraining's rmse: 1.56694\tvalid_1's rmse: 1.57832\n",
      "[6200]\ttraining's rmse: 1.56714\tvalid_1's rmse: 1.58652\n",
      "[6300]\ttraining's rmse: 1.56727\tvalid_1's rmse: 1.5876\n",
      "[6400]\ttraining's rmse: 1.56728\tvalid_1's rmse: 1.59118\n",
      "[6500]\ttraining's rmse: 1.56743\tvalid_1's rmse: 1.59262\n",
      "[6600]\ttraining's rmse: 1.56769\tvalid_1's rmse: 1.59407\n",
      "[6700]\ttraining's rmse: 1.56798\tvalid_1's rmse: 1.59711\n",
      "[6800]\ttraining's rmse: 1.56804\tvalid_1's rmse: 1.60748\n",
      "[6900]\ttraining's rmse: 1.56761\tvalid_1's rmse: 1.6171\n",
      "[7000]\ttraining's rmse: 1.56756\tvalid_1's rmse: 1.61917\n",
      "[7100]\ttraining's rmse: 1.5676\tvalid_1's rmse: 1.62668\n",
      "[7200]\ttraining's rmse: 1.56794\tvalid_1's rmse: 1.63637\n",
      "[7300]\ttraining's rmse: 1.56899\tvalid_1's rmse: 1.63992\n",
      "[7400]\ttraining's rmse: 1.56808\tvalid_1's rmse: 1.65628\n",
      "[7500]\ttraining's rmse: 1.56807\tvalid_1's rmse: 1.66462\n",
      "[7600]\ttraining's rmse: 1.56839\tvalid_1's rmse: 1.66776\n",
      "[7700]\ttraining's rmse: 1.5678\tvalid_1's rmse: 1.69128\n",
      "[7800]\ttraining's rmse: 1.56809\tvalid_1's rmse: 1.70941\n",
      "[7900]\ttraining's rmse: 1.56831\tvalid_1's rmse: 1.73479\n",
      "[8000]\ttraining's rmse: 1.56802\tvalid_1's rmse: 1.74289\n",
      "[8100]\ttraining's rmse: 1.56796\tvalid_1's rmse: 1.746\n",
      "[8200]\ttraining's rmse: 1.56828\tvalid_1's rmse: 1.74512\n",
      "[8300]\ttraining's rmse: 1.56805\tvalid_1's rmse: 1.74054\n",
      "[8400]\ttraining's rmse: 1.56811\tvalid_1's rmse: 1.75548\n",
      "[8500]\ttraining's rmse: 1.56856\tvalid_1's rmse: 1.76372\n",
      "[8600]\ttraining's rmse: 1.56847\tvalid_1's rmse: 1.76899\n",
      "[8700]\ttraining's rmse: 1.56807\tvalid_1's rmse: 1.77767\n",
      "[8800]\ttraining's rmse: 1.56801\tvalid_1's rmse: 1.77781\n",
      "[8900]\ttraining's rmse: 1.56809\tvalid_1's rmse: 1.77675\n",
      "[9000]\ttraining's rmse: 1.56824\tvalid_1's rmse: 1.77716\n",
      "[9100]\ttraining's rmse: 1.56809\tvalid_1's rmse: 1.7771\n",
      "[9200]\ttraining's rmse: 1.56797\tvalid_1's rmse: 1.77303\n",
      "[9300]\ttraining's rmse: 1.56768\tvalid_1's rmse: 1.78353\n",
      "[9400]\ttraining's rmse: 1.56804\tvalid_1's rmse: 1.78758\n",
      "[9500]\ttraining's rmse: 1.56805\tvalid_1's rmse: 1.78702\n",
      "[9600]\ttraining's rmse: 1.56783\tvalid_1's rmse: 1.78755\n",
      "[9700]\ttraining's rmse: 1.56788\tvalid_1's rmse: 1.78773\n",
      "[9800]\ttraining's rmse: 1.56797\tvalid_1's rmse: 1.77056\n",
      "[9900]\ttraining's rmse: 1.56814\tvalid_1's rmse: 1.77461\n",
      "[10000]\ttraining's rmse: 1.56743\tvalid_1's rmse: 1.77816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:29:02,021] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.54695\tvalid_1's rmse: 1.55151\n",
      "[200]\ttraining's rmse: 1.54497\tvalid_1's rmse: 1.54894\n",
      "[300]\ttraining's rmse: 1.54512\tvalid_1's rmse: 1.54871\n",
      "[400]\ttraining's rmse: 1.54417\tvalid_1's rmse: 1.54788\n",
      "[500]\ttraining's rmse: 1.54356\tvalid_1's rmse: 1.54743\n",
      "[600]\ttraining's rmse: 1.54412\tvalid_1's rmse: 1.54743\n",
      "[700]\ttraining's rmse: 1.54472\tvalid_1's rmse: 1.54742\n",
      "[800]\ttraining's rmse: 1.54434\tvalid_1's rmse: 1.54697\n",
      "[900]\ttraining's rmse: 1.54398\tvalid_1's rmse: 1.54661\n",
      "[1000]\ttraining's rmse: 1.54412\tvalid_1's rmse: 1.54686\n",
      "[1100]\ttraining's rmse: 1.54437\tvalid_1's rmse: 1.54675\n",
      "[1200]\ttraining's rmse: 1.54443\tvalid_1's rmse: 1.54644\n",
      "[1300]\ttraining's rmse: 1.5444\tvalid_1's rmse: 1.54638\n",
      "[1400]\ttraining's rmse: 1.54446\tvalid_1's rmse: 1.54659\n",
      "[1500]\ttraining's rmse: 1.54431\tvalid_1's rmse: 1.54647\n",
      "[1600]\ttraining's rmse: 1.54475\tvalid_1's rmse: 1.54692\n",
      "[1700]\ttraining's rmse: 1.54525\tvalid_1's rmse: 1.54703\n",
      "[1800]\ttraining's rmse: 1.54487\tvalid_1's rmse: 1.54707\n",
      "[1900]\ttraining's rmse: 1.54557\tvalid_1's rmse: 1.54729\n",
      "[2000]\ttraining's rmse: 1.54559\tvalid_1's rmse: 1.54712\n",
      "[2100]\ttraining's rmse: 1.54498\tvalid_1's rmse: 1.5469\n",
      "[2200]\ttraining's rmse: 1.54546\tvalid_1's rmse: 1.54694\n",
      "[2300]\ttraining's rmse: 1.54596\tvalid_1's rmse: 1.54704\n",
      "[2400]\ttraining's rmse: 1.54624\tvalid_1's rmse: 1.54709\n",
      "[2500]\ttraining's rmse: 1.54631\tvalid_1's rmse: 1.5471\n",
      "[2600]\ttraining's rmse: 1.54659\tvalid_1's rmse: 1.54703\n",
      "[2700]\ttraining's rmse: 1.54575\tvalid_1's rmse: 1.54624\n",
      "[2800]\ttraining's rmse: 1.5462\tvalid_1's rmse: 1.54635\n",
      "[2900]\ttraining's rmse: 1.54634\tvalid_1's rmse: 1.54623\n",
      "[3000]\ttraining's rmse: 1.54693\tvalid_1's rmse: 1.54631\n",
      "[3100]\ttraining's rmse: 1.54727\tvalid_1's rmse: 1.54666\n",
      "[3200]\ttraining's rmse: 1.54769\tvalid_1's rmse: 1.55137\n",
      "[3300]\ttraining's rmse: 1.54798\tvalid_1's rmse: 1.55064\n",
      "[3400]\ttraining's rmse: 1.54826\tvalid_1's rmse: 1.5557\n",
      "[3500]\ttraining's rmse: 1.54837\tvalid_1's rmse: 1.55638\n",
      "[3600]\ttraining's rmse: 1.5486\tvalid_1's rmse: 1.55578\n",
      "[3700]\ttraining's rmse: 1.54885\tvalid_1's rmse: 1.56293\n",
      "[3800]\ttraining's rmse: 1.54808\tvalid_1's rmse: 1.57133\n",
      "[3900]\ttraining's rmse: 1.54901\tvalid_1's rmse: 1.59257\n",
      "[4000]\ttraining's rmse: 1.54939\tvalid_1's rmse: 1.60485\n",
      "[4100]\ttraining's rmse: 1.54993\tvalid_1's rmse: 1.61065\n",
      "[4200]\ttraining's rmse: 1.54986\tvalid_1's rmse: 1.61534\n",
      "[4300]\ttraining's rmse: 1.54995\tvalid_1's rmse: 1.62955\n",
      "[4400]\ttraining's rmse: 1.55052\tvalid_1's rmse: 1.65858\n",
      "[4500]\ttraining's rmse: 1.55093\tvalid_1's rmse: 1.68131\n",
      "[4600]\ttraining's rmse: 1.55098\tvalid_1's rmse: 1.68965\n",
      "[4700]\ttraining's rmse: 1.55139\tvalid_1's rmse: 1.71412\n",
      "[4800]\ttraining's rmse: 1.55171\tvalid_1's rmse: 1.72359\n",
      "[4900]\ttraining's rmse: 1.55092\tvalid_1's rmse: 1.75338\n",
      "[5000]\ttraining's rmse: 1.55136\tvalid_1's rmse: 1.78654\n",
      "[5100]\ttraining's rmse: 1.55186\tvalid_1's rmse: 1.83006\n",
      "[5200]\ttraining's rmse: 1.5523\tvalid_1's rmse: 1.8972\n",
      "[5300]\ttraining's rmse: 1.55218\tvalid_1's rmse: 1.88985\n",
      "[5400]\ttraining's rmse: 1.55178\tvalid_1's rmse: 1.89875\n",
      "[5500]\ttraining's rmse: 1.55187\tvalid_1's rmse: 1.9348\n",
      "[5600]\ttraining's rmse: 1.552\tvalid_1's rmse: 2.00122\n",
      "[5700]\ttraining's rmse: 1.55182\tvalid_1's rmse: 1.99984\n",
      "[5800]\ttraining's rmse: 1.55157\tvalid_1's rmse: 2.01881\n",
      "[5900]\ttraining's rmse: 1.55135\tvalid_1's rmse: 2.05235\n",
      "[6000]\ttraining's rmse: 1.55167\tvalid_1's rmse: 2.02307\n",
      "[6100]\ttraining's rmse: 1.55168\tvalid_1's rmse: 2.03578\n",
      "[6200]\ttraining's rmse: 1.55144\tvalid_1's rmse: 2.04008\n",
      "[6300]\ttraining's rmse: 1.55139\tvalid_1's rmse: 2.06396\n",
      "[6400]\ttraining's rmse: 1.55126\tvalid_1's rmse: 2.06993\n",
      "[6500]\ttraining's rmse: 1.55203\tvalid_1's rmse: 2.13865\n",
      "[6600]\ttraining's rmse: 1.55182\tvalid_1's rmse: 2.16635\n",
      "[6700]\ttraining's rmse: 1.55178\tvalid_1's rmse: 2.13887\n",
      "[6800]\ttraining's rmse: 1.55187\tvalid_1's rmse: 2.17455\n",
      "[6900]\ttraining's rmse: 1.55138\tvalid_1's rmse: 2.19877\n",
      "[7000]\ttraining's rmse: 1.55212\tvalid_1's rmse: 2.21506\n",
      "[7100]\ttraining's rmse: 1.5514\tvalid_1's rmse: 2.21235\n",
      "[7200]\ttraining's rmse: 1.55128\tvalid_1's rmse: 2.22816\n",
      "[7300]\ttraining's rmse: 1.55078\tvalid_1's rmse: 2.23402\n",
      "[7400]\ttraining's rmse: 1.55083\tvalid_1's rmse: 2.24388\n",
      "[7500]\ttraining's rmse: 1.55037\tvalid_1's rmse: 2.26691\n",
      "[7600]\ttraining's rmse: 1.55121\tvalid_1's rmse: 2.2221\n",
      "[7700]\ttraining's rmse: 1.55108\tvalid_1's rmse: 2.31153\n",
      "[7800]\ttraining's rmse: 1.55146\tvalid_1's rmse: 2.32338\n",
      "[7900]\ttraining's rmse: 1.55142\tvalid_1's rmse: 2.27056\n",
      "[8000]\ttraining's rmse: 1.55113\tvalid_1's rmse: 2.28013\n",
      "[8100]\ttraining's rmse: 1.55155\tvalid_1's rmse: 2.2959\n",
      "[8200]\ttraining's rmse: 1.55123\tvalid_1's rmse: 2.29762\n",
      "[8300]\ttraining's rmse: 1.55084\tvalid_1's rmse: 2.29889\n",
      "[8400]\ttraining's rmse: 1.55118\tvalid_1's rmse: 2.30744\n",
      "[8500]\ttraining's rmse: 1.55083\tvalid_1's rmse: 2.29386\n",
      "[8600]\ttraining's rmse: 1.55107\tvalid_1's rmse: 2.29272\n",
      "[8700]\ttraining's rmse: 1.5512\tvalid_1's rmse: 2.32437\n",
      "[8800]\ttraining's rmse: 1.55092\tvalid_1's rmse: 2.36275\n",
      "[8900]\ttraining's rmse: 1.55129\tvalid_1's rmse: 2.3643\n",
      "[9000]\ttraining's rmse: 1.55097\tvalid_1's rmse: 2.35234\n",
      "[9100]\ttraining's rmse: 1.55098\tvalid_1's rmse: 2.30668\n",
      "[9200]\ttraining's rmse: 1.55111\tvalid_1's rmse: 2.33256\n",
      "[9300]\ttraining's rmse: 1.55103\tvalid_1's rmse: 2.36181\n",
      "[9400]\ttraining's rmse: 1.55152\tvalid_1's rmse: 2.38932\n",
      "[9500]\ttraining's rmse: 1.55122\tvalid_1's rmse: 2.39126\n",
      "[9600]\ttraining's rmse: 1.55154\tvalid_1's rmse: 2.42961\n",
      "[9700]\ttraining's rmse: 1.55155\tvalid_1's rmse: 2.40555\n",
      "[9800]\ttraining's rmse: 1.55134\tvalid_1's rmse: 2.43488\n",
      "[9900]\ttraining's rmse: 1.55146\tvalid_1's rmse: 2.45902\n",
      "[10000]\ttraining's rmse: 1.55147\tvalid_1's rmse: 2.46069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:37:42,320] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.61962\tvalid_1's rmse: 1.61529\n",
      "[200]\ttraining's rmse: 1.58297\tvalid_1's rmse: 1.57734\n",
      "[300]\ttraining's rmse: 1.56247\tvalid_1's rmse: 1.55607\n",
      "[400]\ttraining's rmse: 1.56632\tvalid_1's rmse: 1.55974\n",
      "[500]\ttraining's rmse: 1.56128\tvalid_1's rmse: 1.5546\n",
      "[600]\ttraining's rmse: 1.56226\tvalid_1's rmse: 1.55539\n",
      "[700]\ttraining's rmse: 1.56312\tvalid_1's rmse: 1.556\n",
      "[800]\ttraining's rmse: 1.56256\tvalid_1's rmse: 1.5556\n",
      "[900]\ttraining's rmse: 1.56297\tvalid_1's rmse: 1.55582\n",
      "[1000]\ttraining's rmse: 1.56329\tvalid_1's rmse: 1.55614\n",
      "[1100]\ttraining's rmse: 1.56396\tvalid_1's rmse: 1.55673\n",
      "[1200]\ttraining's rmse: 1.56329\tvalid_1's rmse: 1.55601\n",
      "[1300]\ttraining's rmse: 1.56335\tvalid_1's rmse: 1.55615\n",
      "[1400]\ttraining's rmse: 1.56354\tvalid_1's rmse: 1.55624\n",
      "[1500]\ttraining's rmse: 1.56376\tvalid_1's rmse: 1.55633\n",
      "[1600]\ttraining's rmse: 1.56356\tvalid_1's rmse: 1.55612\n",
      "[1700]\ttraining's rmse: 1.56397\tvalid_1's rmse: 1.55636\n",
      "[1800]\ttraining's rmse: 1.56381\tvalid_1's rmse: 1.55628\n",
      "[1900]\ttraining's rmse: 1.56409\tvalid_1's rmse: 1.55635\n",
      "[2000]\ttraining's rmse: 1.56402\tvalid_1's rmse: 1.55627\n",
      "[2100]\ttraining's rmse: 1.56435\tvalid_1's rmse: 1.5565\n",
      "[2200]\ttraining's rmse: 1.56403\tvalid_1's rmse: 1.55614\n",
      "[2300]\ttraining's rmse: 1.56437\tvalid_1's rmse: 1.55646\n",
      "[2400]\ttraining's rmse: 1.56444\tvalid_1's rmse: 1.55653\n",
      "[2500]\ttraining's rmse: 1.5648\tvalid_1's rmse: 1.55684\n",
      "[2600]\ttraining's rmse: 1.56445\tvalid_1's rmse: 1.55657\n",
      "[2700]\ttraining's rmse: 1.56453\tvalid_1's rmse: 1.55656\n",
      "[2800]\ttraining's rmse: 1.56454\tvalid_1's rmse: 1.55665\n",
      "[2900]\ttraining's rmse: 1.5646\tvalid_1's rmse: 1.55671\n",
      "[3000]\ttraining's rmse: 1.5648\tvalid_1's rmse: 1.55677\n",
      "[3100]\ttraining's rmse: 1.5641\tvalid_1's rmse: 1.55612\n",
      "[3200]\ttraining's rmse: 1.56455\tvalid_1's rmse: 1.55648\n",
      "[3300]\ttraining's rmse: 1.56472\tvalid_1's rmse: 1.55657\n",
      "[3400]\ttraining's rmse: 1.56493\tvalid_1's rmse: 1.55678\n",
      "[3500]\ttraining's rmse: 1.56478\tvalid_1's rmse: 1.55684\n",
      "[3600]\ttraining's rmse: 1.56469\tvalid_1's rmse: 1.55667\n",
      "[3700]\ttraining's rmse: 1.56483\tvalid_1's rmse: 1.55672\n",
      "[3800]\ttraining's rmse: 1.56479\tvalid_1's rmse: 1.5567\n",
      "[3900]\ttraining's rmse: 1.56472\tvalid_1's rmse: 1.5567\n",
      "[4000]\ttraining's rmse: 1.56482\tvalid_1's rmse: 1.55681\n",
      "[4100]\ttraining's rmse: 1.56483\tvalid_1's rmse: 1.55675\n",
      "[4200]\ttraining's rmse: 1.56485\tvalid_1's rmse: 1.55678\n",
      "[4300]\ttraining's rmse: 1.56492\tvalid_1's rmse: 1.55671\n",
      "[4400]\ttraining's rmse: 1.56538\tvalid_1's rmse: 1.55678\n",
      "[4500]\ttraining's rmse: 1.56547\tvalid_1's rmse: 1.55683\n",
      "[4600]\ttraining's rmse: 1.56532\tvalid_1's rmse: 1.55668\n",
      "[4700]\ttraining's rmse: 1.56539\tvalid_1's rmse: 1.55695\n",
      "[4800]\ttraining's rmse: 1.56504\tvalid_1's rmse: 1.55652\n",
      "[4900]\ttraining's rmse: 1.56528\tvalid_1's rmse: 1.55653\n",
      "[5000]\ttraining's rmse: 1.56511\tvalid_1's rmse: 1.5565\n",
      "[5100]\ttraining's rmse: 1.56527\tvalid_1's rmse: 1.55653\n",
      "[5200]\ttraining's rmse: 1.56514\tvalid_1's rmse: 1.55659\n",
      "[5300]\ttraining's rmse: 1.5651\tvalid_1's rmse: 1.55653\n",
      "[5400]\ttraining's rmse: 1.56529\tvalid_1's rmse: 1.55667\n",
      "[5500]\ttraining's rmse: 1.56524\tvalid_1's rmse: 1.55646\n",
      "[5600]\ttraining's rmse: 1.56518\tvalid_1's rmse: 1.55674\n",
      "[5700]\ttraining's rmse: 1.56521\tvalid_1's rmse: 1.55668\n",
      "[5800]\ttraining's rmse: 1.56537\tvalid_1's rmse: 1.55892\n",
      "[5900]\ttraining's rmse: 1.56541\tvalid_1's rmse: 1.56152\n",
      "[6000]\ttraining's rmse: 1.56552\tvalid_1's rmse: 1.56641\n",
      "[6100]\ttraining's rmse: 1.56553\tvalid_1's rmse: 1.56743\n",
      "[6200]\ttraining's rmse: 1.56578\tvalid_1's rmse: 1.56698\n",
      "[6300]\ttraining's rmse: 1.56568\tvalid_1's rmse: 1.56828\n",
      "[6400]\ttraining's rmse: 1.56572\tvalid_1's rmse: 1.56867\n",
      "[6500]\ttraining's rmse: 1.56557\tvalid_1's rmse: 1.57109\n",
      "[6600]\ttraining's rmse: 1.56583\tvalid_1's rmse: 1.57345\n",
      "[6700]\ttraining's rmse: 1.56577\tvalid_1's rmse: 1.57471\n",
      "[6800]\ttraining's rmse: 1.56585\tvalid_1's rmse: 1.57572\n",
      "[6900]\ttraining's rmse: 1.56598\tvalid_1's rmse: 1.58569\n",
      "[7000]\ttraining's rmse: 1.56638\tvalid_1's rmse: 1.5885\n",
      "[7100]\ttraining's rmse: 1.56619\tvalid_1's rmse: 1.59304\n",
      "[7200]\ttraining's rmse: 1.56647\tvalid_1's rmse: 1.59658\n",
      "[7300]\ttraining's rmse: 1.56639\tvalid_1's rmse: 1.6064\n",
      "[7400]\ttraining's rmse: 1.56636\tvalid_1's rmse: 1.60636\n",
      "[7500]\ttraining's rmse: 1.56655\tvalid_1's rmse: 1.60873\n",
      "[7600]\ttraining's rmse: 1.56663\tvalid_1's rmse: 1.61413\n",
      "[7700]\ttraining's rmse: 1.56663\tvalid_1's rmse: 1.61281\n",
      "[7800]\ttraining's rmse: 1.56629\tvalid_1's rmse: 1.62807\n",
      "[7900]\ttraining's rmse: 1.56681\tvalid_1's rmse: 1.64146\n",
      "[8000]\ttraining's rmse: 1.56667\tvalid_1's rmse: 1.64295\n",
      "[8100]\ttraining's rmse: 1.56714\tvalid_1's rmse: 1.64927\n",
      "[8200]\ttraining's rmse: 1.56712\tvalid_1's rmse: 1.66176\n",
      "[8300]\ttraining's rmse: 1.56737\tvalid_1's rmse: 1.66713\n",
      "[8400]\ttraining's rmse: 1.56722\tvalid_1's rmse: 1.68237\n",
      "[8500]\ttraining's rmse: 1.56718\tvalid_1's rmse: 1.68253\n",
      "[8600]\ttraining's rmse: 1.56703\tvalid_1's rmse: 1.68609\n",
      "[8700]\ttraining's rmse: 1.5674\tvalid_1's rmse: 1.68966\n",
      "[8800]\ttraining's rmse: 1.56667\tvalid_1's rmse: 1.69646\n",
      "[8900]\ttraining's rmse: 1.56741\tvalid_1's rmse: 1.6979\n",
      "[9000]\ttraining's rmse: 1.56719\tvalid_1's rmse: 1.69706\n",
      "[9100]\ttraining's rmse: 1.56729\tvalid_1's rmse: 1.70665\n",
      "[9200]\ttraining's rmse: 1.56702\tvalid_1's rmse: 1.71697\n",
      "[9300]\ttraining's rmse: 1.5672\tvalid_1's rmse: 1.71982\n",
      "[9400]\ttraining's rmse: 1.56656\tvalid_1's rmse: 1.72904\n",
      "[9500]\ttraining's rmse: 1.56648\tvalid_1's rmse: 1.72869\n",
      "[9600]\ttraining's rmse: 1.56734\tvalid_1's rmse: 1.73165\n",
      "[9700]\ttraining's rmse: 1.5669\tvalid_1's rmse: 1.73218\n",
      "[9800]\ttraining's rmse: 1.56677\tvalid_1's rmse: 1.73776\n",
      "[9900]\ttraining's rmse: 1.567\tvalid_1's rmse: 1.74075\n",
      "[10000]\ttraining's rmse: 1.56732\tvalid_1's rmse: 1.74303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:45:16,654] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.61475\tvalid_1's rmse: 1.62913\n",
      "[200]\ttraining's rmse: 1.52872\tvalid_1's rmse: 1.54867\n",
      "[300]\ttraining's rmse: 1.52431\tvalid_1's rmse: 1.54267\n",
      "[400]\ttraining's rmse: 1.52518\tvalid_1's rmse: 1.54263\n",
      "[500]\ttraining's rmse: 1.52476\tvalid_1's rmse: 1.54151\n",
      "[600]\ttraining's rmse: 1.52889\tvalid_1's rmse: 1.54511\n",
      "[700]\ttraining's rmse: 1.52706\tvalid_1's rmse: 1.54271\n",
      "[800]\ttraining's rmse: 1.5266\tvalid_1's rmse: 1.54151\n",
      "[900]\ttraining's rmse: 1.52795\tvalid_1's rmse: 1.5421\n",
      "[1000]\ttraining's rmse: 1.52882\tvalid_1's rmse: 1.54255\n",
      "[1100]\ttraining's rmse: 1.52827\tvalid_1's rmse: 1.54181\n",
      "[1200]\ttraining's rmse: 1.52818\tvalid_1's rmse: 1.54141\n",
      "[1300]\ttraining's rmse: 1.52872\tvalid_1's rmse: 1.54155\n",
      "[1400]\ttraining's rmse: 1.52907\tvalid_1's rmse: 1.5418\n",
      "[1500]\ttraining's rmse: 1.52904\tvalid_1's rmse: 1.54153\n",
      "[1600]\ttraining's rmse: 1.52965\tvalid_1's rmse: 1.54207\n",
      "[1700]\ttraining's rmse: 1.52954\tvalid_1's rmse: 1.54183\n",
      "[1800]\ttraining's rmse: 1.52996\tvalid_1's rmse: 1.54204\n",
      "[1900]\ttraining's rmse: 1.53002\tvalid_1's rmse: 1.54187\n",
      "[2000]\ttraining's rmse: 1.5302\tvalid_1's rmse: 1.54192\n",
      "[2100]\ttraining's rmse: 1.53038\tvalid_1's rmse: 1.54192\n",
      "[2200]\ttraining's rmse: 1.53062\tvalid_1's rmse: 1.54192\n",
      "[2300]\ttraining's rmse: 1.53069\tvalid_1's rmse: 1.54187\n",
      "[2400]\ttraining's rmse: 1.53102\tvalid_1's rmse: 1.54211\n",
      "[2500]\ttraining's rmse: 1.53106\tvalid_1's rmse: 1.54204\n",
      "[2600]\ttraining's rmse: 1.53132\tvalid_1's rmse: 1.54217\n",
      "[2700]\ttraining's rmse: 1.53136\tvalid_1's rmse: 1.54214\n",
      "[2800]\ttraining's rmse: 1.53148\tvalid_1's rmse: 1.54218\n",
      "[2900]\ttraining's rmse: 1.53159\tvalid_1's rmse: 1.54217\n",
      "[3000]\ttraining's rmse: 1.53149\tvalid_1's rmse: 1.54208\n",
      "[3100]\ttraining's rmse: 1.53157\tvalid_1's rmse: 1.54202\n",
      "[3200]\ttraining's rmse: 1.53168\tvalid_1's rmse: 1.54204\n",
      "[3300]\ttraining's rmse: 1.53184\tvalid_1's rmse: 1.54212\n",
      "[3400]\ttraining's rmse: 1.53189\tvalid_1's rmse: 1.54212\n",
      "[3500]\ttraining's rmse: 1.53191\tvalid_1's rmse: 1.5421\n",
      "[3600]\ttraining's rmse: 1.53186\tvalid_1's rmse: 1.542\n",
      "[3700]\ttraining's rmse: 1.53201\tvalid_1's rmse: 1.54205\n",
      "[3800]\ttraining's rmse: 1.53198\tvalid_1's rmse: 1.54212\n",
      "[3900]\ttraining's rmse: 1.53208\tvalid_1's rmse: 1.54209\n",
      "[4000]\ttraining's rmse: 1.53202\tvalid_1's rmse: 1.54202\n",
      "[4100]\ttraining's rmse: 1.53215\tvalid_1's rmse: 1.54208\n",
      "[4200]\ttraining's rmse: 1.53214\tvalid_1's rmse: 1.54208\n",
      "[4300]\ttraining's rmse: 1.53218\tvalid_1's rmse: 1.5421\n",
      "[4400]\ttraining's rmse: 1.53202\tvalid_1's rmse: 1.54194\n",
      "[4500]\ttraining's rmse: 1.53204\tvalid_1's rmse: 1.54194\n",
      "[4600]\ttraining's rmse: 1.53204\tvalid_1's rmse: 1.54193\n",
      "[4700]\ttraining's rmse: 1.53212\tvalid_1's rmse: 1.54195\n",
      "[4800]\ttraining's rmse: 1.53208\tvalid_1's rmse: 1.54199\n",
      "[4900]\ttraining's rmse: 1.53215\tvalid_1's rmse: 1.54198\n",
      "[5000]\ttraining's rmse: 1.53226\tvalid_1's rmse: 1.54206\n",
      "[5100]\ttraining's rmse: 1.53218\tvalid_1's rmse: 1.54198\n",
      "[5200]\ttraining's rmse: 1.53218\tvalid_1's rmse: 1.54193\n",
      "[5300]\ttraining's rmse: 1.53216\tvalid_1's rmse: 1.54196\n",
      "[5400]\ttraining's rmse: 1.53217\tvalid_1's rmse: 1.54192\n",
      "[5500]\ttraining's rmse: 1.53229\tvalid_1's rmse: 1.54199\n",
      "[5600]\ttraining's rmse: 1.53226\tvalid_1's rmse: 1.54197\n",
      "[5700]\ttraining's rmse: 1.53231\tvalid_1's rmse: 1.54199\n",
      "[5800]\ttraining's rmse: 1.53236\tvalid_1's rmse: 1.54208\n",
      "[5900]\ttraining's rmse: 1.53241\tvalid_1's rmse: 1.54208\n",
      "[6000]\ttraining's rmse: 1.53246\tvalid_1's rmse: 1.54213\n",
      "[6100]\ttraining's rmse: 1.53246\tvalid_1's rmse: 1.54216\n",
      "[6200]\ttraining's rmse: 1.53255\tvalid_1's rmse: 1.54221\n",
      "[6300]\ttraining's rmse: 1.53248\tvalid_1's rmse: 1.54212\n",
      "[6400]\ttraining's rmse: 1.53252\tvalid_1's rmse: 1.54216\n",
      "[6500]\ttraining's rmse: 1.5326\tvalid_1's rmse: 1.54228\n",
      "[6600]\ttraining's rmse: 1.53252\tvalid_1's rmse: 1.54218\n",
      "[6700]\ttraining's rmse: 1.53257\tvalid_1's rmse: 1.5422\n",
      "[6800]\ttraining's rmse: 1.53252\tvalid_1's rmse: 1.54212\n",
      "[6900]\ttraining's rmse: 1.53254\tvalid_1's rmse: 1.54212\n",
      "[7000]\ttraining's rmse: 1.53246\tvalid_1's rmse: 1.54213\n",
      "[7100]\ttraining's rmse: 1.53254\tvalid_1's rmse: 1.54224\n",
      "[7200]\ttraining's rmse: 1.5325\tvalid_1's rmse: 1.54218\n",
      "[7300]\ttraining's rmse: 1.53255\tvalid_1's rmse: 1.5422\n",
      "[7400]\ttraining's rmse: 1.53258\tvalid_1's rmse: 1.54221\n",
      "[7500]\ttraining's rmse: 1.53257\tvalid_1's rmse: 1.5422\n",
      "[7600]\ttraining's rmse: 1.53256\tvalid_1's rmse: 1.5422\n",
      "[7700]\ttraining's rmse: 1.53256\tvalid_1's rmse: 1.54218\n",
      "[7800]\ttraining's rmse: 1.53255\tvalid_1's rmse: 1.54216\n",
      "[7900]\ttraining's rmse: 1.53262\tvalid_1's rmse: 1.54223\n",
      "[8000]\ttraining's rmse: 1.53262\tvalid_1's rmse: 1.54222\n",
      "[8100]\ttraining's rmse: 1.5327\tvalid_1's rmse: 1.54224\n",
      "[8200]\ttraining's rmse: 1.5327\tvalid_1's rmse: 1.54221\n",
      "[8300]\ttraining's rmse: 1.53274\tvalid_1's rmse: 1.5422\n",
      "[8400]\ttraining's rmse: 1.53271\tvalid_1's rmse: 1.54216\n",
      "[8500]\ttraining's rmse: 1.53273\tvalid_1's rmse: 1.54219\n",
      "[8600]\ttraining's rmse: 1.53279\tvalid_1's rmse: 1.54221\n",
      "[8700]\ttraining's rmse: 1.53273\tvalid_1's rmse: 1.54222\n",
      "[8800]\ttraining's rmse: 1.53277\tvalid_1's rmse: 1.54226\n",
      "[8900]\ttraining's rmse: 1.53274\tvalid_1's rmse: 1.54231\n",
      "[9000]\ttraining's rmse: 1.53276\tvalid_1's rmse: 1.54229\n",
      "[9100]\ttraining's rmse: 1.5327\tvalid_1's rmse: 1.5423\n",
      "[9200]\ttraining's rmse: 1.53273\tvalid_1's rmse: 1.54233\n",
      "[9300]\ttraining's rmse: 1.5327\tvalid_1's rmse: 1.54229\n",
      "[9400]\ttraining's rmse: 1.53269\tvalid_1's rmse: 1.54229\n",
      "[9500]\ttraining's rmse: 1.5327\tvalid_1's rmse: 1.54226\n",
      "[9600]\ttraining's rmse: 1.53281\tvalid_1's rmse: 1.54233\n",
      "[9700]\ttraining's rmse: 1.53278\tvalid_1's rmse: 1.54231\n",
      "[9800]\ttraining's rmse: 1.53275\tvalid_1's rmse: 1.54226\n",
      "[9900]\ttraining's rmse: 1.53279\tvalid_1's rmse: 1.54228\n",
      "[10000]\ttraining's rmse: 1.53283\tvalid_1's rmse: 1.54228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:54:37,577] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.58628\tvalid_1's rmse: 1.57391\n",
      "[200]\ttraining's rmse: 1.58569\tvalid_1's rmse: 1.57329\n",
      "[300]\ttraining's rmse: 1.58467\tvalid_1's rmse: 1.57253\n",
      "[400]\ttraining's rmse: 1.58479\tvalid_1's rmse: 1.57255\n",
      "[500]\ttraining's rmse: 1.58523\tvalid_1's rmse: 1.57301\n",
      "[600]\ttraining's rmse: 1.5851\tvalid_1's rmse: 1.57234\n",
      "[700]\ttraining's rmse: 1.58646\tvalid_1's rmse: 1.57368\n",
      "[800]\ttraining's rmse: 1.58583\tvalid_1's rmse: 1.57334\n",
      "[900]\ttraining's rmse: 1.58667\tvalid_1's rmse: 1.57388\n",
      "[1000]\ttraining's rmse: 1.58465\tvalid_1's rmse: 1.57191\n",
      "[1100]\ttraining's rmse: 1.58444\tvalid_1's rmse: 1.57207\n",
      "[1200]\ttraining's rmse: 1.58382\tvalid_1's rmse: 1.57805\n",
      "[1300]\ttraining's rmse: 1.58436\tvalid_1's rmse: 1.57812\n",
      "[1400]\ttraining's rmse: 1.58513\tvalid_1's rmse: 1.57859\n",
      "[1500]\ttraining's rmse: 1.58501\tvalid_1's rmse: 1.57857\n",
      "[1600]\ttraining's rmse: 1.58559\tvalid_1's rmse: 1.57961\n",
      "[1700]\ttraining's rmse: 1.58481\tvalid_1's rmse: 1.5797\n",
      "[1800]\ttraining's rmse: 1.58587\tvalid_1's rmse: 1.57829\n",
      "[1900]\ttraining's rmse: 1.58411\tvalid_1's rmse: 1.62242\n",
      "[2000]\ttraining's rmse: 1.58483\tvalid_1's rmse: 1.7067\n",
      "[2100]\ttraining's rmse: 1.58486\tvalid_1's rmse: 1.81164\n",
      "[2200]\ttraining's rmse: 1.58507\tvalid_1's rmse: 1.83579\n",
      "[2300]\ttraining's rmse: 1.58554\tvalid_1's rmse: 1.84435\n",
      "[2400]\ttraining's rmse: 1.58592\tvalid_1's rmse: 1.89068\n",
      "[2500]\ttraining's rmse: 1.58581\tvalid_1's rmse: 2.1305\n",
      "[2600]\ttraining's rmse: 1.58574\tvalid_1's rmse: 2.12617\n",
      "[2700]\ttraining's rmse: 1.58631\tvalid_1's rmse: 2.14115\n",
      "[2800]\ttraining's rmse: 1.58764\tvalid_1's rmse: 2.17283\n",
      "[2900]\ttraining's rmse: 1.58553\tvalid_1's rmse: 2.17781\n",
      "[3000]\ttraining's rmse: 1.58619\tvalid_1's rmse: 2.18862\n",
      "[3100]\ttraining's rmse: 1.58688\tvalid_1's rmse: 2.22603\n",
      "[3200]\ttraining's rmse: 1.58666\tvalid_1's rmse: 2.29268\n",
      "[3300]\ttraining's rmse: 1.58598\tvalid_1's rmse: 2.3397\n",
      "[3400]\ttraining's rmse: 1.58393\tvalid_1's rmse: 2.28953\n",
      "[3500]\ttraining's rmse: 1.58399\tvalid_1's rmse: 2.38171\n",
      "[3600]\ttraining's rmse: 1.58397\tvalid_1's rmse: 2.43463\n",
      "[3700]\ttraining's rmse: 1.5836\tvalid_1's rmse: 2.4272\n",
      "[3800]\ttraining's rmse: 1.58329\tvalid_1's rmse: 2.42057\n",
      "[3900]\ttraining's rmse: 1.58453\tvalid_1's rmse: 2.45098\n",
      "[4000]\ttraining's rmse: 1.58422\tvalid_1's rmse: 2.43799\n",
      "[4100]\ttraining's rmse: 1.58356\tvalid_1's rmse: 2.55593\n",
      "[4200]\ttraining's rmse: 1.58392\tvalid_1's rmse: 2.6102\n",
      "[4300]\ttraining's rmse: 1.58462\tvalid_1's rmse: 2.57898\n",
      "[4400]\ttraining's rmse: 1.58362\tvalid_1's rmse: 2.61612\n",
      "[4500]\ttraining's rmse: 1.58365\tvalid_1's rmse: 2.62088\n",
      "[4600]\ttraining's rmse: 1.58399\tvalid_1's rmse: 2.68645\n",
      "[4700]\ttraining's rmse: 1.58442\tvalid_1's rmse: 2.6494\n",
      "[4800]\ttraining's rmse: 1.58367\tvalid_1's rmse: 2.67345\n",
      "[4900]\ttraining's rmse: 1.58333\tvalid_1's rmse: 2.6388\n",
      "[5000]\ttraining's rmse: 1.58283\tvalid_1's rmse: 2.68113\n",
      "[5100]\ttraining's rmse: 1.58351\tvalid_1's rmse: 2.70588\n",
      "[5200]\ttraining's rmse: 1.58268\tvalid_1's rmse: 2.76789\n",
      "[5300]\ttraining's rmse: 1.58236\tvalid_1's rmse: 2.75989\n",
      "[5400]\ttraining's rmse: 1.58215\tvalid_1's rmse: 2.75866\n",
      "[5500]\ttraining's rmse: 1.58315\tvalid_1's rmse: 2.8048\n",
      "[5600]\ttraining's rmse: 1.58204\tvalid_1's rmse: 2.7451\n",
      "[5700]\ttraining's rmse: 1.58209\tvalid_1's rmse: 2.79874\n",
      "[5800]\ttraining's rmse: 1.58191\tvalid_1's rmse: 2.81247\n",
      "[5900]\ttraining's rmse: 1.58212\tvalid_1's rmse: 2.85165\n",
      "[6000]\ttraining's rmse: 1.58146\tvalid_1's rmse: 2.81396\n",
      "[6100]\ttraining's rmse: 1.5815\tvalid_1's rmse: 2.8148\n",
      "[6200]\ttraining's rmse: 1.58172\tvalid_1's rmse: 2.81534\n",
      "[6300]\ttraining's rmse: 1.58237\tvalid_1's rmse: 2.78381\n",
      "[6400]\ttraining's rmse: 1.58564\tvalid_1's rmse: 2.84861\n",
      "[6500]\ttraining's rmse: 1.58539\tvalid_1's rmse: 2.8454\n",
      "[6600]\ttraining's rmse: 1.58469\tvalid_1's rmse: 2.92441\n",
      "[6700]\ttraining's rmse: 1.58295\tvalid_1's rmse: 2.93457\n",
      "[6800]\ttraining's rmse: 1.58166\tvalid_1's rmse: 2.9598\n",
      "[6900]\ttraining's rmse: 1.58228\tvalid_1's rmse: 2.99644\n",
      "[7000]\ttraining's rmse: 1.58216\tvalid_1's rmse: 3.00611\n",
      "[7100]\ttraining's rmse: 1.58203\tvalid_1's rmse: 2.92927\n",
      "[7200]\ttraining's rmse: 1.58238\tvalid_1's rmse: 2.98223\n",
      "[7300]\ttraining's rmse: 1.58196\tvalid_1's rmse: 3.01638\n",
      "[7400]\ttraining's rmse: 1.58273\tvalid_1's rmse: 3.0077\n",
      "[7500]\ttraining's rmse: 1.58254\tvalid_1's rmse: 3.03388\n",
      "[7600]\ttraining's rmse: 1.58196\tvalid_1's rmse: 3.01276\n",
      "[7700]\ttraining's rmse: 1.58192\tvalid_1's rmse: 3.03422\n",
      "[7800]\ttraining's rmse: 1.58183\tvalid_1's rmse: 3.05718\n",
      "[7900]\ttraining's rmse: 1.58159\tvalid_1's rmse: 3.06739\n",
      "[8000]\ttraining's rmse: 1.58186\tvalid_1's rmse: 3.08373\n",
      "[8100]\ttraining's rmse: 1.58123\tvalid_1's rmse: 3.06274\n",
      "[8200]\ttraining's rmse: 1.58166\tvalid_1's rmse: 3.05467\n",
      "[8300]\ttraining's rmse: 1.58202\tvalid_1's rmse: 3.09585\n",
      "[8400]\ttraining's rmse: 1.58196\tvalid_1's rmse: 3.04392\n",
      "[8500]\ttraining's rmse: 1.58033\tvalid_1's rmse: 3.04689\n",
      "[8600]\ttraining's rmse: 1.58194\tvalid_1's rmse: 3.0765\n",
      "[8700]\ttraining's rmse: 1.58134\tvalid_1's rmse: 3.07512\n",
      "[8800]\ttraining's rmse: 1.58121\tvalid_1's rmse: 3.13856\n",
      "[8900]\ttraining's rmse: 1.58115\tvalid_1's rmse: 3.15223\n",
      "[9000]\ttraining's rmse: 1.58168\tvalid_1's rmse: 3.11707\n",
      "[9100]\ttraining's rmse: 1.58199\tvalid_1's rmse: 3.10317\n",
      "[9200]\ttraining's rmse: 1.58133\tvalid_1's rmse: 3.12667\n",
      "[9300]\ttraining's rmse: 1.58084\tvalid_1's rmse: 3.13795\n",
      "[9400]\ttraining's rmse: 1.58137\tvalid_1's rmse: 3.16633\n",
      "[9500]\ttraining's rmse: 1.58111\tvalid_1's rmse: 3.21863\n",
      "[9600]\ttraining's rmse: 1.58296\tvalid_1's rmse: 3.15972\n",
      "[9700]\ttraining's rmse: 1.58202\tvalid_1's rmse: 3.22978\n",
      "[9800]\ttraining's rmse: 1.58099\tvalid_1's rmse: 3.22399\n",
      "[9900]\ttraining's rmse: 1.58125\tvalid_1's rmse: 3.27695\n",
      "[10000]\ttraining's rmse: 1.58199\tvalid_1's rmse: 3.22041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 12:57:29,216] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.78563\tvalid_1's rmse: 1.80024\n",
      "[200]\ttraining's rmse: 1.56482\tvalid_1's rmse: 1.57759\n",
      "[300]\ttraining's rmse: 1.54246\tvalid_1's rmse: 1.55372\n",
      "[400]\ttraining's rmse: 1.54117\tvalid_1's rmse: 1.55131\n",
      "[500]\ttraining's rmse: 1.53795\tvalid_1's rmse: 1.54709\n",
      "[600]\ttraining's rmse: 1.5429\tvalid_1's rmse: 1.55154\n",
      "[700]\ttraining's rmse: 1.5411\tvalid_1's rmse: 1.54914\n",
      "[800]\ttraining's rmse: 1.54073\tvalid_1's rmse: 1.54808\n",
      "[900]\ttraining's rmse: 1.54188\tvalid_1's rmse: 1.54858\n",
      "[1000]\ttraining's rmse: 1.54244\tvalid_1's rmse: 1.54875\n",
      "[1100]\ttraining's rmse: 1.54173\tvalid_1's rmse: 1.54754\n",
      "[1200]\ttraining's rmse: 1.54116\tvalid_1's rmse: 1.5466\n",
      "[1300]\ttraining's rmse: 1.54121\tvalid_1's rmse: 1.5463\n",
      "[1400]\ttraining's rmse: 1.54211\tvalid_1's rmse: 1.5469\n",
      "[1500]\ttraining's rmse: 1.54138\tvalid_1's rmse: 1.54601\n",
      "[1600]\ttraining's rmse: 1.54199\tvalid_1's rmse: 1.5462\n",
      "[1700]\ttraining's rmse: 1.54206\tvalid_1's rmse: 1.54604\n",
      "[1800]\ttraining's rmse: 1.542\tvalid_1's rmse: 1.54568\n",
      "[1900]\ttraining's rmse: 1.54311\tvalid_1's rmse: 1.54664\n",
      "[2000]\ttraining's rmse: 1.543\tvalid_1's rmse: 1.54642\n",
      "[2100]\ttraining's rmse: 1.54252\tvalid_1's rmse: 1.5457\n",
      "[2200]\ttraining's rmse: 1.54307\tvalid_1's rmse: 1.546\n",
      "[2300]\ttraining's rmse: 1.54275\tvalid_1's rmse: 1.54553\n",
      "[2400]\ttraining's rmse: 1.54347\tvalid_1's rmse: 1.54614\n",
      "[2500]\ttraining's rmse: 1.54348\tvalid_1's rmse: 1.54601\n",
      "[2600]\ttraining's rmse: 1.54371\tvalid_1's rmse: 1.54612\n",
      "[2700]\ttraining's rmse: 1.54394\tvalid_1's rmse: 1.54624\n",
      "[2800]\ttraining's rmse: 1.54375\tvalid_1's rmse: 1.5459\n",
      "[2900]\ttraining's rmse: 1.54402\tvalid_1's rmse: 1.54614\n",
      "[3000]\ttraining's rmse: 1.54399\tvalid_1's rmse: 1.546\n",
      "[3100]\ttraining's rmse: 1.54447\tvalid_1's rmse: 1.5464\n",
      "[3200]\ttraining's rmse: 1.54446\tvalid_1's rmse: 1.54628\n",
      "[3300]\ttraining's rmse: 1.5446\tvalid_1's rmse: 1.54634\n",
      "[3400]\ttraining's rmse: 1.54469\tvalid_1's rmse: 1.5464\n",
      "[3500]\ttraining's rmse: 1.54493\tvalid_1's rmse: 1.5465\n",
      "[3600]\ttraining's rmse: 1.54479\tvalid_1's rmse: 1.54637\n",
      "[3700]\ttraining's rmse: 1.54498\tvalid_1's rmse: 1.54659\n",
      "[3800]\ttraining's rmse: 1.54502\tvalid_1's rmse: 1.54652\n",
      "[3900]\ttraining's rmse: 1.54512\tvalid_1's rmse: 1.54653\n",
      "[4000]\ttraining's rmse: 1.54523\tvalid_1's rmse: 1.54662\n",
      "[4100]\ttraining's rmse: 1.54532\tvalid_1's rmse: 1.54663\n",
      "[4200]\ttraining's rmse: 1.54553\tvalid_1's rmse: 1.54682\n",
      "[4300]\ttraining's rmse: 1.54549\tvalid_1's rmse: 1.54673\n",
      "[4400]\ttraining's rmse: 1.54549\tvalid_1's rmse: 1.5467\n",
      "[4500]\ttraining's rmse: 1.54542\tvalid_1's rmse: 1.54655\n",
      "[4600]\ttraining's rmse: 1.5454\tvalid_1's rmse: 1.54654\n",
      "[4700]\ttraining's rmse: 1.54557\tvalid_1's rmse: 1.54665\n",
      "[4800]\ttraining's rmse: 1.54559\tvalid_1's rmse: 1.54655\n",
      "[4900]\ttraining's rmse: 1.5456\tvalid_1's rmse: 1.54653\n",
      "[5000]\ttraining's rmse: 1.54579\tvalid_1's rmse: 1.54666\n",
      "[5100]\ttraining's rmse: 1.54584\tvalid_1's rmse: 1.54663\n",
      "[5200]\ttraining's rmse: 1.54586\tvalid_1's rmse: 1.5466\n",
      "[5300]\ttraining's rmse: 1.54573\tvalid_1's rmse: 1.54642\n",
      "[5400]\ttraining's rmse: 1.54586\tvalid_1's rmse: 1.54652\n",
      "[5500]\ttraining's rmse: 1.54599\tvalid_1's rmse: 1.54661\n",
      "[5600]\ttraining's rmse: 1.54598\tvalid_1's rmse: 1.54654\n",
      "[5700]\ttraining's rmse: 1.54605\tvalid_1's rmse: 1.54659\n",
      "[5800]\ttraining's rmse: 1.54614\tvalid_1's rmse: 1.54665\n",
      "[5900]\ttraining's rmse: 1.54619\tvalid_1's rmse: 1.54666\n",
      "[6000]\ttraining's rmse: 1.54623\tvalid_1's rmse: 1.5467\n",
      "[6100]\ttraining's rmse: 1.54612\tvalid_1's rmse: 1.54667\n",
      "[6200]\ttraining's rmse: 1.54624\tvalid_1's rmse: 1.54676\n",
      "[6300]\ttraining's rmse: 1.54628\tvalid_1's rmse: 1.54678\n",
      "[6400]\ttraining's rmse: 1.5463\tvalid_1's rmse: 1.5468\n",
      "[6500]\ttraining's rmse: 1.54637\tvalid_1's rmse: 1.54684\n",
      "[6600]\ttraining's rmse: 1.54636\tvalid_1's rmse: 1.54679\n",
      "[6700]\ttraining's rmse: 1.54647\tvalid_1's rmse: 1.54685\n",
      "[6800]\ttraining's rmse: 1.54647\tvalid_1's rmse: 1.54684\n",
      "[6900]\ttraining's rmse: 1.54641\tvalid_1's rmse: 1.54678\n",
      "[7000]\ttraining's rmse: 1.54646\tvalid_1's rmse: 1.5468\n",
      "[7100]\ttraining's rmse: 1.54646\tvalid_1's rmse: 1.54682\n",
      "[7200]\ttraining's rmse: 1.54636\tvalid_1's rmse: 1.54675\n",
      "[7300]\ttraining's rmse: 1.54649\tvalid_1's rmse: 1.5468\n",
      "[7400]\ttraining's rmse: 1.54649\tvalid_1's rmse: 1.54679\n",
      "[7500]\ttraining's rmse: 1.54644\tvalid_1's rmse: 1.54672\n",
      "[7600]\ttraining's rmse: 1.54647\tvalid_1's rmse: 1.54674\n",
      "[7700]\ttraining's rmse: 1.54654\tvalid_1's rmse: 1.54683\n",
      "[7800]\ttraining's rmse: 1.54652\tvalid_1's rmse: 1.54678\n",
      "[7900]\ttraining's rmse: 1.54664\tvalid_1's rmse: 1.54685\n",
      "[8000]\ttraining's rmse: 1.5466\tvalid_1's rmse: 1.54681\n",
      "[8100]\ttraining's rmse: 1.54664\tvalid_1's rmse: 1.54681\n",
      "[8200]\ttraining's rmse: 1.54668\tvalid_1's rmse: 1.54682\n",
      "[8300]\ttraining's rmse: 1.5466\tvalid_1's rmse: 1.54679\n",
      "[8400]\ttraining's rmse: 1.54658\tvalid_1's rmse: 1.54679\n",
      "[8500]\ttraining's rmse: 1.54665\tvalid_1's rmse: 1.54683\n",
      "[8600]\ttraining's rmse: 1.54665\tvalid_1's rmse: 1.54684\n",
      "[8700]\ttraining's rmse: 1.54672\tvalid_1's rmse: 1.54685\n",
      "[8800]\ttraining's rmse: 1.54675\tvalid_1's rmse: 1.54686\n",
      "[8900]\ttraining's rmse: 1.54677\tvalid_1's rmse: 1.54684\n",
      "[9000]\ttraining's rmse: 1.54674\tvalid_1's rmse: 1.54681\n",
      "[9100]\ttraining's rmse: 1.54683\tvalid_1's rmse: 1.54685\n",
      "[9200]\ttraining's rmse: 1.5468\tvalid_1's rmse: 1.5468\n",
      "[9300]\ttraining's rmse: 1.54685\tvalid_1's rmse: 1.54683\n",
      "[9400]\ttraining's rmse: 1.54685\tvalid_1's rmse: 1.54682\n",
      "[9500]\ttraining's rmse: 1.54683\tvalid_1's rmse: 1.54687\n",
      "[9600]\ttraining's rmse: 1.54689\tvalid_1's rmse: 1.54689\n",
      "[9700]\ttraining's rmse: 1.5469\tvalid_1's rmse: 1.5469\n",
      "[9800]\ttraining's rmse: 1.5469\tvalid_1's rmse: 1.54686\n",
      "[9900]\ttraining's rmse: 1.54694\tvalid_1's rmse: 1.54687\n",
      "[10000]\ttraining's rmse: 1.547\tvalid_1's rmse: 1.54691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 13:05:53,549] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[100]\ttraining's rmse: 1.59325\tvalid_1's rmse: 1.59439\n",
      "[200]\ttraining's rmse: 1.58935\tvalid_1's rmse: 1.60193\n",
      "[300]\ttraining's rmse: 1.5899\tvalid_1's rmse: 1.70593\n",
      "[400]\ttraining's rmse: 1.58918\tvalid_1's rmse: 2.16416\n",
      "[500]\ttraining's rmse: 1.59064\tvalid_1's rmse: 2.16555\n",
      "[600]\ttraining's rmse: 1.5905\tvalid_1's rmse: 2.3314\n",
      "[700]\ttraining's rmse: 1.58947\tvalid_1's rmse: 2.63284\n",
      "[800]\ttraining's rmse: 1.591\tvalid_1's rmse: 2.65755\n",
      "[900]\ttraining's rmse: 1.58915\tvalid_1's rmse: 2.72426\n",
      "[1000]\ttraining's rmse: 1.58872\tvalid_1's rmse: 2.83453\n",
      "[1100]\ttraining's rmse: 1.58974\tvalid_1's rmse: 3.03318\n",
      "[1200]\ttraining's rmse: 1.58956\tvalid_1's rmse: 3.07837\n",
      "[1300]\ttraining's rmse: 1.5888\tvalid_1's rmse: 3.09247\n",
      "[1400]\ttraining's rmse: 1.5889\tvalid_1's rmse: 3.21582\n",
      "[1500]\ttraining's rmse: 1.59348\tvalid_1's rmse: 3.27885\n",
      "[1600]\ttraining's rmse: 1.58686\tvalid_1's rmse: 3.31782\n",
      "[1700]\ttraining's rmse: 1.58919\tvalid_1's rmse: 3.35662\n",
      "[1800]\ttraining's rmse: 1.58693\tvalid_1's rmse: 3.56702\n",
      "[1900]\ttraining's rmse: 1.58733\tvalid_1's rmse: 3.55171\n",
      "[2000]\ttraining's rmse: 1.58718\tvalid_1's rmse: 3.46863\n",
      "[2100]\ttraining's rmse: 1.58794\tvalid_1's rmse: 3.52498\n",
      "[2200]\ttraining's rmse: 1.58636\tvalid_1's rmse: 3.55343\n",
      "[2300]\ttraining's rmse: 1.58607\tvalid_1's rmse: 3.56308\n",
      "[2400]\ttraining's rmse: 1.58683\tvalid_1's rmse: 3.51466\n",
      "[2500]\ttraining's rmse: 1.5879\tvalid_1's rmse: 3.60095\n",
      "[2600]\ttraining's rmse: 1.58637\tvalid_1's rmse: 3.5543\n",
      "[2700]\ttraining's rmse: 1.58756\tvalid_1's rmse: 3.56713\n",
      "[2800]\ttraining's rmse: 1.58702\tvalid_1's rmse: 3.66725\n",
      "[2900]\ttraining's rmse: 1.58997\tvalid_1's rmse: 3.6963\n",
      "[3000]\ttraining's rmse: 1.58756\tvalid_1's rmse: 3.69674\n",
      "[3100]\ttraining's rmse: 1.58762\tvalid_1's rmse: 3.59401\n",
      "[3200]\ttraining's rmse: 1.58697\tvalid_1's rmse: 3.68046\n",
      "[3300]\ttraining's rmse: 1.58694\tvalid_1's rmse: 3.71056\n",
      "[3400]\ttraining's rmse: 1.58914\tvalid_1's rmse: 3.71204\n",
      "[3500]\ttraining's rmse: 1.5865\tvalid_1's rmse: 3.81869\n",
      "[3600]\ttraining's rmse: 1.58833\tvalid_1's rmse: 3.70859\n",
      "[3700]\ttraining's rmse: 1.58707\tvalid_1's rmse: 3.83995\n",
      "[3800]\ttraining's rmse: 1.58719\tvalid_1's rmse: 3.75067\n",
      "[3900]\ttraining's rmse: 1.58728\tvalid_1's rmse: 3.76235\n",
      "[4000]\ttraining's rmse: 1.60359\tvalid_1's rmse: 3.85439\n",
      "[4100]\ttraining's rmse: 1.58791\tvalid_1's rmse: 3.9049\n",
      "[4200]\ttraining's rmse: 1.58652\tvalid_1's rmse: 3.85733\n",
      "[4300]\ttraining's rmse: 1.59091\tvalid_1's rmse: 3.85924\n",
      "[4400]\ttraining's rmse: 1.58713\tvalid_1's rmse: 3.56087\n",
      "[4500]\ttraining's rmse: 1.58961\tvalid_1's rmse: 3.87019\n",
      "[4600]\ttraining's rmse: 1.58567\tvalid_1's rmse: 3.89563\n",
      "[4700]\ttraining's rmse: 1.58657\tvalid_1's rmse: 3.93023\n",
      "[4800]\ttraining's rmse: 1.58664\tvalid_1's rmse: 3.78255\n",
      "[4900]\ttraining's rmse: 1.58768\tvalid_1's rmse: 3.90038\n",
      "[5000]\ttraining's rmse: 1.58652\tvalid_1's rmse: 3.80607\n",
      "[5100]\ttraining's rmse: 1.58618\tvalid_1's rmse: 3.98496\n",
      "[5200]\ttraining's rmse: 1.58608\tvalid_1's rmse: 3.82623\n",
      "[5300]\ttraining's rmse: 1.58667\tvalid_1's rmse: 4.04752\n",
      "[5400]\ttraining's rmse: 1.58677\tvalid_1's rmse: 3.87346\n",
      "[5500]\ttraining's rmse: 1.59741\tvalid_1's rmse: 3.86101\n",
      "[5600]\ttraining's rmse: 1.58647\tvalid_1's rmse: 3.76226\n",
      "[5700]\ttraining's rmse: 1.5901\tvalid_1's rmse: 4.02632\n",
      "[5800]\ttraining's rmse: 1.5869\tvalid_1's rmse: 3.74012\n",
      "[5900]\ttraining's rmse: 1.5984\tvalid_1's rmse: 3.54415\n",
      "[6000]\ttraining's rmse: 1.58682\tvalid_1's rmse: 3.75484\n",
      "[6100]\ttraining's rmse: 1.58743\tvalid_1's rmse: 3.93642\n",
      "[6200]\ttraining's rmse: 1.58761\tvalid_1's rmse: 3.97022\n",
      "[6300]\ttraining's rmse: 1.58707\tvalid_1's rmse: 3.63113\n",
      "[6400]\ttraining's rmse: 1.5857\tvalid_1's rmse: 3.81444\n",
      "[6500]\ttraining's rmse: 1.58987\tvalid_1's rmse: 3.48432\n",
      "[6600]\ttraining's rmse: 1.59923\tvalid_1's rmse: 3.62455\n",
      "[6700]\ttraining's rmse: 1.60799\tvalid_1's rmse: 3.63061\n",
      "[6800]\ttraining's rmse: 1.58562\tvalid_1's rmse: 4.00287\n",
      "[6900]\ttraining's rmse: 1.5861\tvalid_1's rmse: 4.05447\n",
      "[7000]\ttraining's rmse: 1.58512\tvalid_1's rmse: 3.56453\n",
      "[7100]\ttraining's rmse: 1.58594\tvalid_1's rmse: 3.62137\n",
      "[7200]\ttraining's rmse: 1.60262\tvalid_1's rmse: 3.37889\n",
      "[7300]\ttraining's rmse: 1.58778\tvalid_1's rmse: 3.58375\n",
      "[7400]\ttraining's rmse: 1.58694\tvalid_1's rmse: 3.85437\n",
      "[7500]\ttraining's rmse: 1.5856\tvalid_1's rmse: 3.97921\n",
      "[7600]\ttraining's rmse: 1.58606\tvalid_1's rmse: 3.95952\n",
      "[7700]\ttraining's rmse: 1.6219\tvalid_1's rmse: 3.77976\n",
      "[7800]\ttraining's rmse: 1.58514\tvalid_1's rmse: 3.63921\n",
      "[7900]\ttraining's rmse: 1.58561\tvalid_1's rmse: 3.75624\n",
      "[8000]\ttraining's rmse: 1.59126\tvalid_1's rmse: 3.69743\n",
      "[8100]\ttraining's rmse: 1.58888\tvalid_1's rmse: 3.58159\n",
      "[8200]\ttraining's rmse: 1.58633\tvalid_1's rmse: 4.00333\n",
      "[8300]\ttraining's rmse: 1.58646\tvalid_1's rmse: 3.85303\n",
      "[8400]\ttraining's rmse: 1.58548\tvalid_1's rmse: 3.65584\n",
      "[8500]\ttraining's rmse: 1.58468\tvalid_1's rmse: 3.82748\n",
      "[8600]\ttraining's rmse: 1.58494\tvalid_1's rmse: 3.53745\n",
      "[8700]\ttraining's rmse: 1.58564\tvalid_1's rmse: 3.95738\n",
      "[8800]\ttraining's rmse: 1.58682\tvalid_1's rmse: 3.65412\n",
      "[8900]\ttraining's rmse: 1.58651\tvalid_1's rmse: 3.72849\n",
      "[9000]\ttraining's rmse: 1.58543\tvalid_1's rmse: 3.7805\n",
      "[9100]\ttraining's rmse: 1.58595\tvalid_1's rmse: 3.69824\n",
      "[9200]\ttraining's rmse: 1.58696\tvalid_1's rmse: 3.53109\n",
      "[9300]\ttraining's rmse: 1.5856\tvalid_1's rmse: 3.82655\n",
      "[9400]\ttraining's rmse: 1.58595\tvalid_1's rmse: 3.66579\n",
      "[9500]\ttraining's rmse: 1.58826\tvalid_1's rmse: 3.50676\n",
      "[9600]\ttraining's rmse: 1.58492\tvalid_1's rmse: 3.9841\n",
      "[9700]\ttraining's rmse: 1.58582\tvalid_1's rmse: 3.87544\n",
      "[9800]\ttraining's rmse: 1.58551\tvalid_1's rmse: 3.82782\n",
      "[9900]\ttraining's rmse: 1.58935\tvalid_1's rmse: 3.84188\n",
      "[10000]\ttraining's rmse: 1.62139\tvalid_1's rmse: 3.39989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-02-11 13:08:16,432] Setting trial status as TrialState.FAIL because of the following error: KeyError(\"['outliers'] not in index\",)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\optuna\\study.py\", line 409, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-3-b04324314658>\", line 65, in kfold_lightgbm\n",
      "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 1958, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py\", line 2002, in _getitem_array\n",
      "    indexer = self.loc._convert_to_indexer(key, axis=1)\n",
      "  File \"C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1231, in _convert_to_indexer\n",
      "    raise KeyError('%s not in index' % objarr[mask])\n",
      "KeyError: \"['outliers'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(kfold_lightgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importance_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-93e19de30e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m cols = (feature_importance_df[[\"feature\", \"importance\"]]\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         .sort_values(by=\"importance\", ascending=False)[:20].index)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_importance_df' is not defined"
     ]
    }
   ],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "sub_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"../output/submit_lgb\"+str(n)+\"_optuna.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
