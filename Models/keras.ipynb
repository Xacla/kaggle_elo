{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train_1.csv')\n",
    "test = pd.read_csv('../input/test_1.csv')\n",
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naoki Tomita\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is: 222\n",
      "Starting Neural Network\n",
      "Train on 161533 samples, validate on 40384 samples\n",
      "Epoch 1/25\n",
      "161533/161533 [==============================] - 20s 122us/step - loss: 14.2814 - mean_squared_error: 14.2814 - val_loss: 14.5480 - val_mean_squared_error: 14.5480\n",
      "Epoch 2/25\n",
      "161533/161533 [==============================] - 17s 103us/step - loss: 14.0332 - mean_squared_error: 14.0332 - val_loss: 14.3969 - val_mean_squared_error: 14.3969\n",
      "Epoch 3/25\n",
      "161533/161533 [==============================] - 16s 101us/step - loss: 13.9761 - mean_squared_error: 13.9761 - val_loss: 14.4797 - val_mean_squared_error: 14.4797\n",
      "Epoch 4/25\n",
      "161533/161533 [==============================] - 17s 104us/step - loss: 13.9363 - mean_squared_error: 13.9363 - val_loss: 14.5792 - val_mean_squared_error: 14.5792\n",
      "Epoch 5/25\n",
      "161533/161533 [==============================] - 17s 103us/step - loss: 13.9155 - mean_squared_error: 13.9155 - val_loss: 14.3455 - val_mean_squared_error: 14.3455\n",
      "Epoch 6/25\n",
      "161533/161533 [==============================] - 16s 102us/step - loss: 13.9063 - mean_squared_error: 13.9063 - val_loss: 14.5378 - val_mean_squared_error: 14.5378\n",
      "Epoch 7/25\n",
      "161533/161533 [==============================] - 16s 102us/step - loss: 13.9202 - mean_squared_error: 13.9202 - val_loss: 14.4701 - val_mean_squared_error: 14.4701\n",
      "Epoch 8/25\n",
      "161533/161533 [==============================] - 16s 102us/step - loss: 13.9003 - mean_squared_error: 13.9003 - val_loss: 14.3070 - val_mean_squared_error: 14.3070\n",
      "Epoch 9/25\n",
      "161533/161533 [==============================] - 17s 104us/step - loss: 13.8954 - mean_squared_error: 13.8954 - val_loss: 14.6184 - val_mean_squared_error: 14.6184\n",
      "Epoch 10/25\n",
      "161533/161533 [==============================] - 17s 104us/step - loss: 13.8843 - mean_squared_error: 13.8843 - val_loss: 14.4568 - val_mean_squared_error: 14.4568\n",
      "Epoch 11/25\n",
      "161533/161533 [==============================] - 16s 101us/step - loss: 13.9137 - mean_squared_error: 13.9137 - val_loss: 14.3708 - val_mean_squared_error: 14.3708\n"
     ]
    }
   ],
   "source": [
    "y = target\n",
    "\n",
    "train_columns = [c for c in train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "train_df = train[train_columns]\n",
    "test_df = test[train_columns]\n",
    "\n",
    "#####Handling Missing Values#####     \n",
    "\n",
    "for i in range(len(train_df.columns)):\n",
    "    train_df.iloc[:,i] = (train_df.iloc[:,i]).fillna(-1)\n",
    "\n",
    "for i in range(len(test_df.columns)):\n",
    "    test_df.iloc[:,i] = (test_df.iloc[:,i]).fillna(-1)    \n",
    "    \n",
    "####Normalizing the values####\n",
    "\n",
    "mmScale = MinMaxScaler()\n",
    "\n",
    "n = train_df.shape[1]\n",
    "print('n is:',n)\n",
    "\n",
    "x_train = mmScale.fit_transform(train_df)\n",
    "x_test = mmScale.transform(test_df)\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "#####################Early Stopping ########################\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "#####Artificial Neural Networks Implementation#####\n",
    "print(\"Starting Neural Network\")\n",
    "\n",
    "model_n = Sequential()\n",
    "#Want to use an expotential linear unit instead of the usual relu\n",
    "#model_n.add( Dense( n, activation='relu', input_shape=(n,) ) )\n",
    "model_n.add( Dense( n, activation='tanh', input_shape=(n,) ) )\n",
    "model_n.add(BatchNormalization())\n",
    "model_n.add( Dense( int(0.5*n), activation='relu' ) )\n",
    "model_n.add(LeakyReLU(alpha=.0011))\n",
    "\n",
    "model_n.add(Dropout(0.5))\n",
    "\n",
    "model_n.add(Dense(1, activation='linear'))\n",
    "model_n.compile(loss='mse', optimizer='Adadelta',  metrics=['mse'])\n",
    "        \n",
    "\n",
    "model_n.fit(x_train, y, epochs=25,verbose=1, batch_size=32,validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "predictions = model_n.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input//sample_submission.csv\")\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit_keras.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE 3.805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
