{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tomita/kaggle/kaggle_elo/Models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import gc \n",
    "import time\n",
    "plt.style.use('ggplot') # Lets make our plots pretty\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'first_active_month', 'card_id', 'feature_1', 'feature_2',\n",
      "       'feature_3', 'target', 'elapsed_time', 'outliers',\n",
      "       'hist_transactions_count',\n",
      "       ...\n",
      "       'installments_purchase_amount_max', 'installments_purchase_amount_std',\n",
      "       'city_id_purchase_amount_mean', 'city_id_purchase_amount_min',\n",
      "       'city_id_purchase_amount_max', 'city_id_purchase_amount_std',\n",
      "       'category_1_installments_mean', 'category_1_installments_min',\n",
      "       'category_1_installments_max', 'category_1_installments_std'],\n",
      "      dtype='object', length=226)\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataframes\n",
    "train = pd.read_csv('../input/train_1.csv')\n",
    "test = pd.read_csv('../input/test_1.csv')\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "del train['target']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7 ,\n",
    "         \"bagging_seed\": 2015,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": 4,\n",
    "         \"verbosity\": -1,\n",
    "          \"device\":'GPU',\n",
    "        \"max_bin\":63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.72531\tvalid_1's rmse: 3.79299\n",
      "[200]\ttraining's rmse: 3.6569\tvalid_1's rmse: 3.75052\n",
      "[300]\ttraining's rmse: 3.60946\tvalid_1's rmse: 3.72862\n",
      "[400]\ttraining's rmse: 3.57401\tvalid_1's rmse: 3.71573\n",
      "[500]\ttraining's rmse: 3.54592\tvalid_1's rmse: 3.70706\n",
      "[600]\ttraining's rmse: 3.52244\tvalid_1's rmse: 3.70074\n",
      "[700]\ttraining's rmse: 3.50158\tvalid_1's rmse: 3.69662\n",
      "[800]\ttraining's rmse: 3.48306\tvalid_1's rmse: 3.69329\n",
      "[900]\ttraining's rmse: 3.46646\tvalid_1's rmse: 3.69003\n",
      "[1000]\ttraining's rmse: 3.45123\tvalid_1's rmse: 3.68809\n",
      "[1100]\ttraining's rmse: 3.43661\tvalid_1's rmse: 3.68647\n",
      "[1200]\ttraining's rmse: 3.42331\tvalid_1's rmse: 3.68469\n",
      "[1300]\ttraining's rmse: 3.41009\tvalid_1's rmse: 3.68313\n",
      "[1400]\ttraining's rmse: 3.39743\tvalid_1's rmse: 3.68214\n",
      "[1500]\ttraining's rmse: 3.38602\tvalid_1's rmse: 3.68136\n",
      "[1600]\ttraining's rmse: 3.37419\tvalid_1's rmse: 3.68074\n",
      "[1700]\ttraining's rmse: 3.36291\tvalid_1's rmse: 3.68001\n",
      "[1800]\ttraining's rmse: 3.35168\tvalid_1's rmse: 3.67936\n",
      "[1900]\ttraining's rmse: 3.3405\tvalid_1's rmse: 3.6786\n",
      "[2000]\ttraining's rmse: 3.33015\tvalid_1's rmse: 3.67802\n",
      "[2100]\ttraining's rmse: 3.3198\tvalid_1's rmse: 3.67788\n",
      "[2200]\ttraining's rmse: 3.30943\tvalid_1's rmse: 3.67735\n",
      "[2300]\ttraining's rmse: 3.2992\tvalid_1's rmse: 3.67714\n",
      "[2400]\ttraining's rmse: 3.289\tvalid_1's rmse: 3.67677\n",
      "[2500]\ttraining's rmse: 3.27905\tvalid_1's rmse: 3.67659\n",
      "[2600]\ttraining's rmse: 3.26962\tvalid_1's rmse: 3.67632\n",
      "[2700]\ttraining's rmse: 3.26003\tvalid_1's rmse: 3.67603\n",
      "[2800]\ttraining's rmse: 3.25076\tvalid_1's rmse: 3.67607\n",
      "[2900]\ttraining's rmse: 3.24176\tvalid_1's rmse: 3.67582\n",
      "[3000]\ttraining's rmse: 3.23233\tvalid_1's rmse: 3.67586\n",
      "[3100]\ttraining's rmse: 3.22352\tvalid_1's rmse: 3.67565\n",
      "[3200]\ttraining's rmse: 3.21508\tvalid_1's rmse: 3.67556\n",
      "[3300]\ttraining's rmse: 3.20566\tvalid_1's rmse: 3.67541\n",
      "[3400]\ttraining's rmse: 3.1969\tvalid_1's rmse: 3.67544\n",
      "[3500]\ttraining's rmse: 3.18816\tvalid_1's rmse: 3.67522\n",
      "[3600]\ttraining's rmse: 3.17949\tvalid_1's rmse: 3.67501\n",
      "[3700]\ttraining's rmse: 3.17059\tvalid_1's rmse: 3.67505\n",
      "[3800]\ttraining's rmse: 3.16246\tvalid_1's rmse: 3.67523\n",
      "Early stopping, best iteration is:\n",
      "[3652]\ttraining's rmse: 3.17496\tvalid_1's rmse: 3.67488\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.74324\tvalid_1's rmse: 3.72028\n",
      "[200]\ttraining's rmse: 3.67209\tvalid_1's rmse: 3.6808\n",
      "[300]\ttraining's rmse: 3.62458\tvalid_1's rmse: 3.66178\n",
      "[400]\ttraining's rmse: 3.58948\tvalid_1's rmse: 3.65087\n",
      "[500]\ttraining's rmse: 3.56038\tvalid_1's rmse: 3.64325\n",
      "[600]\ttraining's rmse: 3.53706\tvalid_1's rmse: 3.6386\n",
      "[700]\ttraining's rmse: 3.51595\tvalid_1's rmse: 3.63375\n",
      "[800]\ttraining's rmse: 3.49777\tvalid_1's rmse: 3.63016\n",
      "[900]\ttraining's rmse: 3.48088\tvalid_1's rmse: 3.62741\n",
      "[1000]\ttraining's rmse: 3.4655\tvalid_1's rmse: 3.62513\n",
      "[1100]\ttraining's rmse: 3.45147\tvalid_1's rmse: 3.62315\n",
      "[1200]\ttraining's rmse: 3.43834\tvalid_1's rmse: 3.62161\n",
      "[1300]\ttraining's rmse: 3.42539\tvalid_1's rmse: 3.62021\n",
      "[1400]\ttraining's rmse: 3.41326\tvalid_1's rmse: 3.61959\n",
      "[1500]\ttraining's rmse: 3.40065\tvalid_1's rmse: 3.61873\n",
      "[1600]\ttraining's rmse: 3.38892\tvalid_1's rmse: 3.61778\n",
      "[1700]\ttraining's rmse: 3.37785\tvalid_1's rmse: 3.61706\n",
      "[1800]\ttraining's rmse: 3.36682\tvalid_1's rmse: 3.61672\n",
      "[1900]\ttraining's rmse: 3.35617\tvalid_1's rmse: 3.61633\n",
      "[2000]\ttraining's rmse: 3.34532\tvalid_1's rmse: 3.6158\n",
      "[2100]\ttraining's rmse: 3.33459\tvalid_1's rmse: 3.61542\n",
      "[2200]\ttraining's rmse: 3.32431\tvalid_1's rmse: 3.61495\n",
      "[2300]\ttraining's rmse: 3.31418\tvalid_1's rmse: 3.61488\n",
      "[2400]\ttraining's rmse: 3.30392\tvalid_1's rmse: 3.61473\n",
      "[2500]\ttraining's rmse: 3.29375\tvalid_1's rmse: 3.61424\n",
      "[2600]\ttraining's rmse: 3.28373\tvalid_1's rmse: 3.61405\n",
      "[2700]\ttraining's rmse: 3.27464\tvalid_1's rmse: 3.61403\n",
      "[2800]\ttraining's rmse: 3.26498\tvalid_1's rmse: 3.61422\n",
      "Early stopping, best iteration is:\n",
      "[2611]\ttraining's rmse: 3.28275\tvalid_1's rmse: 3.61395\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.7475\tvalid_1's rmse: 3.69629\n",
      "[200]\ttraining's rmse: 3.67741\tvalid_1's rmse: 3.65743\n",
      "[300]\ttraining's rmse: 3.62926\tvalid_1's rmse: 3.63884\n",
      "[400]\ttraining's rmse: 3.59378\tvalid_1's rmse: 3.62745\n",
      "[500]\ttraining's rmse: 3.56597\tvalid_1's rmse: 3.62035\n",
      "[600]\ttraining's rmse: 3.54187\tvalid_1's rmse: 3.6152\n",
      "[700]\ttraining's rmse: 3.52139\tvalid_1's rmse: 3.61096\n",
      "[800]\ttraining's rmse: 3.50293\tvalid_1's rmse: 3.60743\n",
      "[900]\ttraining's rmse: 3.4861\tvalid_1's rmse: 3.60518\n",
      "[1000]\ttraining's rmse: 3.47054\tvalid_1's rmse: 3.60333\n",
      "[1100]\ttraining's rmse: 3.45605\tvalid_1's rmse: 3.60156\n",
      "[1200]\ttraining's rmse: 3.44231\tvalid_1's rmse: 3.60012\n",
      "[1300]\ttraining's rmse: 3.42907\tvalid_1's rmse: 3.59877\n",
      "[1400]\ttraining's rmse: 3.41593\tvalid_1's rmse: 3.59769\n",
      "[1500]\ttraining's rmse: 3.40398\tvalid_1's rmse: 3.59729\n",
      "[1600]\ttraining's rmse: 3.39213\tvalid_1's rmse: 3.59678\n",
      "[1700]\ttraining's rmse: 3.38058\tvalid_1's rmse: 3.59666\n",
      "[1800]\ttraining's rmse: 3.36931\tvalid_1's rmse: 3.59643\n",
      "[1900]\ttraining's rmse: 3.35876\tvalid_1's rmse: 3.59562\n",
      "[2000]\ttraining's rmse: 3.34803\tvalid_1's rmse: 3.59551\n",
      "[2100]\ttraining's rmse: 3.33716\tvalid_1's rmse: 3.59491\n",
      "[2200]\ttraining's rmse: 3.32714\tvalid_1's rmse: 3.59473\n",
      "[2300]\ttraining's rmse: 3.3169\tvalid_1's rmse: 3.59454\n",
      "[2400]\ttraining's rmse: 3.30608\tvalid_1's rmse: 3.59446\n",
      "[2500]\ttraining's rmse: 3.29621\tvalid_1's rmse: 3.59414\n",
      "[2600]\ttraining's rmse: 3.28658\tvalid_1's rmse: 3.59415\n",
      "[2700]\ttraining's rmse: 3.27699\tvalid_1's rmse: 3.59442\n",
      "Early stopping, best iteration is:\n",
      "[2519]\ttraining's rmse: 3.29452\tvalid_1's rmse: 3.59406\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.69956\tvalid_1's rmse: 3.89342\n",
      "[200]\ttraining's rmse: 3.6298\tvalid_1's rmse: 3.84948\n",
      "[300]\ttraining's rmse: 3.58182\tvalid_1's rmse: 3.82548\n",
      "[400]\ttraining's rmse: 3.54671\tvalid_1's rmse: 3.81302\n",
      "[500]\ttraining's rmse: 3.51789\tvalid_1's rmse: 3.80509\n",
      "[600]\ttraining's rmse: 3.49354\tvalid_1's rmse: 3.79979\n",
      "[700]\ttraining's rmse: 3.47175\tvalid_1's rmse: 3.79646\n",
      "[800]\ttraining's rmse: 3.45315\tvalid_1's rmse: 3.79306\n",
      "[900]\ttraining's rmse: 3.43629\tvalid_1's rmse: 3.79069\n",
      "[1000]\ttraining's rmse: 3.42078\tvalid_1's rmse: 3.78895\n",
      "[1100]\ttraining's rmse: 3.40642\tvalid_1's rmse: 3.78731\n",
      "[1200]\ttraining's rmse: 3.39246\tvalid_1's rmse: 3.78666\n",
      "[1300]\ttraining's rmse: 3.37895\tvalid_1's rmse: 3.78627\n",
      "[1400]\ttraining's rmse: 3.36646\tvalid_1's rmse: 3.78541\n",
      "[1500]\ttraining's rmse: 3.35445\tvalid_1's rmse: 3.78513\n",
      "[1600]\ttraining's rmse: 3.34224\tvalid_1's rmse: 3.7847\n",
      "[1700]\ttraining's rmse: 3.33148\tvalid_1's rmse: 3.78464\n",
      "[1800]\ttraining's rmse: 3.32047\tvalid_1's rmse: 3.78428\n",
      "[1900]\ttraining's rmse: 3.30958\tvalid_1's rmse: 3.78373\n",
      "[2000]\ttraining's rmse: 3.29914\tvalid_1's rmse: 3.78348\n",
      "[2100]\ttraining's rmse: 3.28923\tvalid_1's rmse: 3.78339\n",
      "[2200]\ttraining's rmse: 3.27899\tvalid_1's rmse: 3.78289\n",
      "[2300]\ttraining's rmse: 3.26903\tvalid_1's rmse: 3.78242\n",
      "[2400]\ttraining's rmse: 3.25931\tvalid_1's rmse: 3.78235\n",
      "[2500]\ttraining's rmse: 3.24941\tvalid_1's rmse: 3.78205\n",
      "[2600]\ttraining's rmse: 3.23979\tvalid_1's rmse: 3.78195\n",
      "[2700]\ttraining's rmse: 3.23048\tvalid_1's rmse: 3.78208\n",
      "Early stopping, best iteration is:\n",
      "[2534]\ttraining's rmse: 3.24617\tvalid_1's rmse: 3.78193\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.74444\tvalid_1's rmse: 3.70929\n",
      "[200]\ttraining's rmse: 3.67345\tvalid_1's rmse: 3.67196\n",
      "[300]\ttraining's rmse: 3.62503\tvalid_1's rmse: 3.65306\n",
      "[400]\ttraining's rmse: 3.58903\tvalid_1's rmse: 3.64331\n",
      "[500]\ttraining's rmse: 3.56074\tvalid_1's rmse: 3.63744\n",
      "[600]\ttraining's rmse: 3.53636\tvalid_1's rmse: 3.63256\n",
      "[700]\ttraining's rmse: 3.5152\tvalid_1's rmse: 3.6287\n",
      "[800]\ttraining's rmse: 3.49619\tvalid_1's rmse: 3.62538\n",
      "[900]\ttraining's rmse: 3.47918\tvalid_1's rmse: 3.62296\n",
      "[1000]\ttraining's rmse: 3.46367\tvalid_1's rmse: 3.62114\n",
      "[1100]\ttraining's rmse: 3.4496\tvalid_1's rmse: 3.6198\n",
      "[1200]\ttraining's rmse: 3.4365\tvalid_1's rmse: 3.6185\n",
      "[1300]\ttraining's rmse: 3.42293\tvalid_1's rmse: 3.61776\n",
      "[1400]\ttraining's rmse: 3.41072\tvalid_1's rmse: 3.61729\n",
      "[1500]\ttraining's rmse: 3.39898\tvalid_1's rmse: 3.61673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttraining's rmse: 3.38734\tvalid_1's rmse: 3.6165\n",
      "[1700]\ttraining's rmse: 3.37582\tvalid_1's rmse: 3.61614\n",
      "[1800]\ttraining's rmse: 3.36454\tvalid_1's rmse: 3.61597\n",
      "[1900]\ttraining's rmse: 3.35348\tvalid_1's rmse: 3.6158\n",
      "[2000]\ttraining's rmse: 3.34278\tvalid_1's rmse: 3.61564\n",
      "[2100]\ttraining's rmse: 3.33238\tvalid_1's rmse: 3.61522\n",
      "[2200]\ttraining's rmse: 3.32226\tvalid_1's rmse: 3.61497\n",
      "[2300]\ttraining's rmse: 3.31217\tvalid_1's rmse: 3.61491\n",
      "[2400]\ttraining's rmse: 3.30231\tvalid_1's rmse: 3.61483\n",
      "[2500]\ttraining's rmse: 3.29247\tvalid_1's rmse: 3.61445\n",
      "[2600]\ttraining's rmse: 3.28278\tvalid_1's rmse: 3.61453\n",
      "[2700]\ttraining's rmse: 3.27317\tvalid_1's rmse: 3.61455\n",
      "[2800]\ttraining's rmse: 3.26384\tvalid_1's rmse: 3.61425\n",
      "[2900]\ttraining's rmse: 3.25445\tvalid_1's rmse: 3.6142\n",
      "[3000]\ttraining's rmse: 3.24462\tvalid_1's rmse: 3.61425\n",
      "Early stopping, best iteration is:\n",
      "[2885]\ttraining's rmse: 3.25588\tvalid_1's rmse: 3.61408\n",
      "経過時間：290.1821677684784\n",
      "CV score: 3.65642 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "end=time.time()\n",
    "elapsed_time = end-start\n",
    "print(f\"経過時間：{elapsed_time}\")\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=20190208\n",
    "lgbparam ={'task': 'train',\n",
    "            'boosting': 'dart',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.75836372582243783,\n",
    "            'subsample': 0.91158142068248083,\n",
    "            'max_depth': 29,\n",
    "            'top_rate': 0.7790255922489042,\n",
    "            'num_leaves': 562,\n",
    "            'min_child_weight': 27,\n",
    "            'other_rate':0.03564199289369395,\n",
    "            'reg_alpha': 0.72876375065913579,\n",
    "            'colsample_bytree':0.83435723889734326  ,\n",
    "            'min_split_gain': 27.378180277455101,\n",
    "            'reg_lambda': 94.549009291544877,\n",
    "            'min_data_in_leaf': 21,\n",
    "            'verbose': -1,\n",
    "            'seed':seed,\n",
    "            'bagging_seed':seed,\n",
    "            'drop_seed':seed,\n",
    "            'max_bin':255,\n",
    "            'device':'gpu'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/tomita/.pyenv/versions/anaconda3-5.3.1/envs/py36/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.66306\tvalid_1's rmse: 3.74491\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's rmse: 2.65497\tvalid_1's rmse: 3.74842\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.69232\tvalid_1's rmse: 3.59117\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's rmse: 2.67624\tvalid_1's rmse: 3.59881\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.62485\tvalid_1's rmse: 3.87793\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's rmse: 2.60778\tvalid_1's rmse: 3.90702\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.66732\tvalid_1's rmse: 3.7029\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 2.62978\tvalid_1's rmse: 3.73347\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.69718\tvalid_1's rmse: 3.65804\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 2.65033\tvalid_1's rmse: 3.70009\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.6626\tvalid_1's rmse: 3.7724\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 2.6412\tvalid_1's rmse: 3.79271\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.67486\tvalid_1's rmse: 3.72342\n",
      "[200]\ttraining's rmse: 2.71595\tvalid_1's rmse: 3.6982\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's rmse: 2.66394\tvalid_1's rmse: 3.72434\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.65809\tvalid_1's rmse: 3.74535\n",
      "[200]\ttraining's rmse: 2.71054\tvalid_1's rmse: 3.72103\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's rmse: 2.64283\tvalid_1's rmse: 3.75097\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.67404\tvalid_1's rmse: 3.70064\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's rmse: 2.64658\tvalid_1's rmse: 3.72912\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.68534\tvalid_1's rmse: 3.6433\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's rmse: 2.66778\tvalid_1's rmse: 3.66829\n",
      "CV score: 3.70166 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4520)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_dart = np.zeros(len(test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 11000\n",
    "    clf = lgb.train(lgbparam, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions_dart += clf.predict(test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:25].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input//sample_submission.csv\")\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit_lgb3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=20190219\n",
    "sub_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit_lgb\"+str(n)+\"_1.csv\", index=False)\n",
    "\n",
    "sub_df1 = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub_df1[\"target\"] = predictions_dart\n",
    "sub_df1.to_csv(\"submit_lgb\"+str(n)+\"_dart.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "----------Stacking 0----------\n",
      "fold n°1\n",
      "----------Stacking 1----------\n",
      "fold n°2\n",
      "----------Stacking 2----------\n",
      "fold n°3\n",
      "----------Stacking 3----------\n",
      "fold n°4\n",
      "----------Stacking 4----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.654572988272359"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "train_stack = np.vstack([oof,oof_lgb]).transpose()\n",
    "test_stack = np.vstack([predictions,predictions_dart]).transpose()\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5,n_repeats=1,random_state=4520)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions_stack = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    print(\"-\" * 10 + \"Stacking \" + str(fold_) + \"-\" * 10)\n",
    "    \n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf.predict(val_data)\n",
    "    predictions_stack += clf.predict(test_stack) / 5\n",
    "\n",
    "np.sqrt(mean_squared_error(target.values, oof_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission['target'] = predictions_stack\n",
    "sample_submission.to_csv('Bayesian_Ridge_Stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission['target'] = (predictions * 0.125+ predictions_dart*0.5+predictions_stack*0.325)*1.1\n",
    "sample_submission.to_csv(\"../output/submit\"+str(n)+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
